### 造成并发的原因
```
(1) 中断

(2) 软中断和tasklet

(3) 内核抢占

(4) 睡眠与用户空间同步

(5) 对称多处理
```

### 编写内核代码需要注意的问题
```
// 这个数据是不是全局的？除了当前线程外，其他线程能不能访问它？
// 这个数据会不会在进程上下文和中断上下文中共享？他是不是要在两个不同的中断处理程序中共享？
// 进程访问数据时可不可以被抢占？被调度的新程序会不会访问同一数据？
// 当前进程会不会阻塞或睡眠在某些资源上？如果是，它会让共享资源出于何种状态？
// 怎么防止数据失控
// 如果这个函数在另一个处理器上被调度会发生什么？
// 如何确保代码远离并发威胁？
```


### linux同步机制
```
同步是靠锁来解决的
https://www.zhihu.com/question/66733477/answer/246635823
https://www.zhihu.com/question/58047327/answer/155607124
https://www.cnblogs.com/wang_yb/archive/2013/05/01/3052865.html

(1) 原子操作(atomic)
    原子操作是由编译器来保证的，保证一个线程对数据的操作不会被其他线程打断。
    原子操作有2类：
        原子整数操作，有32位和64位。头文件分别为<asm/atomic.h>和<asm/atomic64.h>
        原子位操作。头文件 <asm/bitops.h>

(2) 自旋锁(spinlock)
    原子操作只能用于临界区只有一个变量的情况，实际应用中，临界区的情况要复杂的多。
    自旋锁由linux内核提供
    1) 特点
        > 当一个线程获取了锁之后，其他试图获取这个锁的线程一直在循环等待获取这个锁，直至锁重新可用。
        > 由于线程处于一直循环的获取这个锁的状态中，所以会造成CPU处理时间的浪费，因此最好将自旋锁用于能很快处理完的临界区。
        > 自旋锁与中断
            > 禁止中断
                线程获取自旋锁之前，要禁止当前处理器上的中断（防止获取锁的线程和中断形成竞争条件）❗
                比如：当前线程获取自旋锁后，在临界区中被中断处理程序打断，中断处理程序正好也要获取这个锁，于是中断处理程序会等待当前线程释放锁，而当前线程也在等待中断执行完后再执行临界区和释放锁的代码。
            > 禁止中断下半部
                下半部处理和进程上下文共享数据时，由于下半部的处理可以抢占进程上下文的代码，所以进程上下文在对共享数据加锁前要禁止下半部的执行，解锁时再允许下半部的执行。
            > 禁止中断上半部
                中断处理程序（上半部）和下半部处理共享数据时，由于中断处理（上半部）可以抢占下半部的执行，所以下半部在对共享数据加锁前要禁止中断处理（上半部），解锁时再允许中断的执行。
            > tasklet
                同一种tasklet不可能同时运行，所以同类tasklet中的共享数据不需要保护。
                不同类tasklet中共享数据时，需要自旋锁。其中一个tasklet获得锁后，不用禁止其他tasklet的执行，因为同一个处理器上不会有tasklet相互抢占的情况
                同类型或者非同类型的软中断在共享数据时，也不用禁止下半部，因为同一个处理器上不会有软中断互相抢占的情况
        > 自旋锁与抢占
            自旋锁自带禁止内核抢占
        > 死锁
            > 不能递归
                递归的请求同一个自旋锁会自己锁死自己
            > 不能阻塞(内部不能进行上下文切换)
                如果进程获得自旋锁之后再阻塞，那么你的CPU已经拥有了该锁，那么用于释放锁的代码将得不到运行，可能导致死锁的发生
            > 只能由系统内核调用
                自旋锁一定是由系统内核调用的。不可能在用户程序中由用户请求自旋锁。当一个用户进程拥有自旋锁期间，内核是把代码提升到管态的级别上运行。在内部，内核能获取自旋锁，但任何用户都做不到这一点（用户进程可以随时发生上下文切换，或被阻塞）

    2) API
        #include <asm/spinlock.h> 
        spin_lock()	            //获取指定的自旋锁
        spin_lock_irq()	        //禁止本地中断并获取指定的锁
        spin_lock_irqsave()	    //保存本地中断的当前状态，禁止本地中断，并获取指定的锁
        spin_unlock()	        //释放指定的锁
        spin_unlock_irq()	    //释放指定的锁，并激活本地中断
        spin_unlock_irqstore()	//释放指定的锁，并让本地中断恢复到以前状态
        spin_lock_init()	    //动态初始化指定的spinlock_t
        spin_trylock()	        //试图获取指定的锁，如果未获取，则返回0
        spin_is_locked()	    //如果指定的锁当前正在被获取，则返回非0，否则返回0
        spin_lock_bh()          //获取指定锁，并禁止中断下半部
        spin_unlock_bh()        //释放指定锁，并恢复中断下半部
    3) 模型
        while (抢锁(lock) == 没抢到) {
        }
        
(3) 读写自旋锁(rwlock)
    1) 特点
        读写自旋锁除了和普通自旋锁一样有自旋特性以外，还有以下特点： 
        > 读锁之间是共享的, 即一个线程持有了读锁之后，其他线程也可以以读的方式持有这个锁
        > 写锁之间是互斥的, 即一个线程持有了写锁之后，其他线程不能以读或者写的方式持有这个锁
        > 读写锁之间是互斥的, 即一个线程持有了读锁之后，其他线程不能以写的方式持有这个锁
        注：读写锁要分别使用，不能混合使用，否则会造成死锁。
    2) API
        #include <asm/rwlock.h>
        read_lock()                 //获取指定的读锁
        read_lock_irq()	            //禁止本地中断并获得指定读锁
        read_lock_irqsave()	        //存储本地中断的当前状态，禁止本地中断并获得指定读锁
        read_unlock()	            //释放指定的读锁
        read_unlock_irq()	        //释放指定的读锁并激活本地中断
        read_unlock_irqrestore()	//释放指定的读锁并将本地中断恢复到指定前的状态
        write_lock()	            //获得指定的写锁
        write_lock_irq()	        //禁止本地中断并获得指定写锁
        write_lock_irqsave()	    //存储本地中断的当前状态，禁止本地中断并获得指定写锁
        write_unlock()	            //释放指定的写锁
        write_unlock_irq()	        //释放指定的写锁并激活本地中断
        write_unlock_irqrestore()	//释放指定的写锁并将本地中断恢复到指定前的状态
        write_trylock()	            //试图获得指定的写锁；如果写锁不可用，返回非0值
        rwlock_init()	            //初始化指定的rwlock_t
    3) 使用方法
        //定义读写自旋锁
        DEFINE_RWLOCK(mr_rwlock);

        read_lock(&mr_rwlock);
        /* 临界区(只读).... */
        read_unlock(&mr_rwlock);
        
        write_lock(&mr_lock);
        /* 临界区(读写)... */
        write_unlock(&mr_lock);

        //错误用法，混合使用
        /* 获取一个读锁 */
        read_lock(&mr_lock);
        /* 在获取写锁的时候，由于读写锁之间是互斥的，
        * 所以写锁会一直自旋等待读锁的释放，
        * 而此时读锁也在等待写锁获取完成后继续下面的代码。
        * 因此造成了读写锁的互相等待，形成了死锁。
        */
        write_lock(&mr_lock);
        
(4) 信号量
    1) 特点
        > 与自旋锁的区别
            信号量也是一种锁，和自旋锁不同的是，线程获取不到信号量的时候，不会像自旋锁一样循环的去试图获取锁，而是进入睡眠，直至有信号量释放出来时，才会唤醒睡眠的线程，进入临界区执行。
        > 适用于时间长的临界区
            由于使用信号量时，线程会睡眠，所以等待的过程不会占用CPU时间。所以信号量适用于等待时间较长的临界区。
            信号量消耗的CPU时间的地方在于使线程睡眠和唤醒线程，
            如果 （使线程睡眠 + 唤醒线程）的CPU时间 > 线程自旋等待的CPU时间，那么可以考虑使用自旋锁。
        > 二值信号量和计数信号量 
            > 信号量有二值信号量和计数信号量2种，其中二值信号量比较常用。
            > 二值信号量表示信号量只有2个值，即0和1。信号量为1时，表示临界区可用，信号量为0时，表示临界区不可访问。
            > 二值信号量表面看和自旋锁很相似，区别在于争用自旋锁的线程会一直循环尝试获取自旋锁，
            > 而争用信号量的线程在信号量为0时，会进入睡眠，信号量可用时再被唤醒。
            > 计数信号量有个计数值，比如计数值为5，表示同时可以有5个线程访问临界区。
    2) API
        sema_init(struct semaphore *, int)	以指定的计数值初始化动态创建的信号量
        init_MUTEX(struct semaphore *)	以计数值1初始化动态创建的信号量
        init_MUTEX_LOCKED(struct semaphore *)	以计数值0初始化动态创建的信号量（初始为加锁状态）
        down_interruptible(struct semaphore *)	以试图获得指定的信号量，如果信号量已被争用，则进入可中断睡眠状态
        down(struct semaphore *)	以试图获得指定的信号量，如果信号量已被争用，则进入不可中断睡眠状态
        down_trylock(struct semaphore *)	以试图获得指定的信号量，如果信号量已被争用，则立即返回非0值
        up(struct semaphore *)	以释放指定的信号量，如果睡眠队列不空，则唤醒其中一个任务

        //信号量结构体具体如下：
        /* Please don't access any members of this structure directly */
        struct semaphore {
            spinlock_t        lock;
            unsigned int        count;
            struct list_head    wait_list;
        };
        //可以发现信号量结构体中有个自旋锁，这个自旋锁的作用是保证信号量的down和up等操作不会被中断处理程序打断。

    3) 用法
        #include <linux/semaphore.h>

        //定义并声明一个信号量，名字为mr_sem，用于信号量计数
        static DECLARE_MUTEX(mr_sem);

        //试图获取信号量，信号未获取成功时，进入睡眠，此时线程状态为 TASK_INTERRUPTIBLE
        //也可以用down(&mr_sem), 这个方法把线程状态置为 TASK_UNINTERRUPTIBLE 后睡眠
        down_interruptible(&mr_sem);
       
        /* 临界区 ... */
       
        //释放给定的信号量
        up(&mr_sem);

        //一般用的比较多的是down_interruptible()方法，因为以 TASK_UNINTERRUPTIBLE 方式睡眠无法被信号唤醒。


(5) 读写信号量
    读写信号量和信号量之间的关系与读写自旋锁和普通自旋锁之间的关系差不多。
    读写信号量都是二值信号量，即计数值最大为1，增加读者时，计数器不变，增加写者，计数器才减一。也就是说读写信号量保护的临界区，最多只有一个写者，但可以有多个读者。
    读写信号量的相关内容参见：<asm/rwsem.h> 具体实现与硬件体系结构有关。

(6) 互斥体(mutex)
    1) 特点
        > 互斥体
            一种可以睡眠的锁，相当于二值信号量，只是提供的API更加简单，使用的场景也更严格一些。mutex的计数值只能为1，也就是最多只允许一个线程访问临界区
        > 进程上下文
            mutex不能在中断或者下半部中使用，也就是mutex只能在进程上下文中使用
            在同一个上下文中上锁和解锁，不能递归的上锁和解锁
            持有个mutex时，进程不能退出，mutex只能通过官方API来管理，不能自己写代码操作它
        > 互斥体与信号量
            只要满足互斥体的使用场景就尽量优先使用互斥体
        > 互斥体与自旋锁
            低开销加锁          优先使用自旋锁
            短期锁定	        优先使用自旋锁
            长期加锁	        优先使用互斥体
            中断上下文中加锁     使用自旋锁
            持有锁需要睡眠	    使用互斥体
    2) API
        #include <linux/mutex.h>

        mutex_lock(struct mutex *)	    //为指定的mutex上锁，如果锁不可用则睡眠
        mutex_unlock(struct mutex *)	//为指定的mutex解锁
        mutex_trylock(struct mutex *)	//试图获取指定的mutex，如果成功则返回1；否则锁被获取，返回0
        mutex_is_locked(struct mutex *)	//如果锁已被争用，则返回1；否则返回0

(7) 完成变量
    完成变量的机制类似于信号量
    比如一个线程A进入临界区之后，另一个线程B会在完成变量上等待，线程A完成了任务出了临界区之后，使用完成变量来唤醒线程B

(8) 大内核锁
    大内核锁已经不再使用，只存在与一些遗留的代码中

(9) 顺序锁(seqlock, 读写锁的一种优化)
    1) 特点
        > 读锁、写锁
            读锁被获取的情况下，写锁仍然可以被获取(与rwlock主要区别)
            写者与写者之间仍然是互斥的，即如果有写者在进行写操作，其他写者必须自旋在那里，直到写者释放了顺序锁
        > 限制与使用场景
            必须要求被保护的共享资源不含有指针，因为写者可能使得指针失效，但读者如果正要访问该指针，将导致OOPs
            顺序锁优先保证写锁的可用，所以适用于那些读者很多，写者很少，且写优于读的场景。
        > 原理
            读之前和读之后都会检查顺序锁的序列值，如果前后值不符，则说明在读的过程中有写的操作发生，那么读操作会重新执行一次，直至读前后的序列值是一样的。
            do
            {
                /* 读之前获取 顺序锁foo 的序列值 */
                seq = read_seqbegin(&foo);
            ...
            } while(read_seqretry(&foo, seq)); /* 顺序锁foo此时的序列值!=seq 时返回true，反之返回false */
    2) API
        #include <linux/seqlock.h>

        //定义一个顺序锁有两种方式
        seqlock_t seqlock
        seqlock_init(&seqlock)      //方法一
        DEFINE_SEQLOCK(seqlock)     //方法二

        //写
        write_seqlock(&seqlock);
        /* -------- 写临界区 ---------*/
        write_sequnlock(&seqlock);

        //读
        unsigned long seq;
        do { 
            seq = read_seqbegin(&seqlock); 
        /* ---------- 这里读临界区数据 ----------*/
        } while (read_seqretry(&seqlock, seq)); 

(10) RCU
    https://www.ibm.com/developerworks/cn/linux/l-rcu/index.html
    https://zhuanlan.zhihu.com/p/56404913
    https://www.cnblogs.com/qcloud1001/p/7755331.html
    https://cloud.tencent.com/developer/article/1054094
    https://zhuanlan.zhihu.com/p/67520807

    1) 特点
        > 原理
            对于被RCU保护的共享数据结构，读者不需要获得任何锁就可以访问它，但写者在访问它时首先拷贝一个副本，然后对副本进行修改，最后使用一个回调（callback）机制在适当的时机把指向原来数据的指针重新指向新的被修改的数据。这个时机就是所有引用该数据的CPU都退出对共享数据的操作

        > 与rwlock的区别
            写开销较大，适合多读少些
            它既允许多个读者同时访问被保护的数据，又允许多个读者和多个写者同时访问被保护的数据（注意：是否可以有多个写者并行访问取决于写者之间使用的同步机制），读者没有任何同步开销，而写者的同步开销则取决于使用的写者间同步机制。但RCU不能替代rwlock，因为如果写比较多时，对读者的性能提高不能弥补写者导致的损失。

        > 不能阻塞
            读者在访问被RCU保护的共享数据期间不能被阻塞，这是RCU机制得以实现的一个基本前提，也就说当读者在引用被RCU保护的共享数据期间，读者所在的CPU不能发生上下文切换，spinlock和rwlock都需要这样的前提
            写者在访问被RCU保护的共享数据时不需要和读者竞争任何锁，只有在有多于一个写者的情况下需要获得某种锁以与其他写者同步。写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。

        > 宽限期(grace period)
            在一个删除(指的是old version的销毁)动作发生后，它必须等待read_lock临界区结束(读线程结束)，才可以进行销毁操作
            删除 ---> 宽限期 ---> 销毁
            内核把从写操作开始到等待所有读操作结束的这段时间叫做宽限期（Grace Period）。synchronize_rcu函数就是等待宽限期结束的函数    

        > quiescent state
            CPU发生了上下文切换称为经历一个quiescent state
            call_rcu_bh将把 softirq 的执行完毕也认为是一个 quiescent state

        > 怎么识别宽限期
            判断当前没有在临界区也不是针对某一个资源的，而是直接针对整个内核中的所有资源的，当写操作发生的时候，synchronize_rcu开始计算，当所有的CPU都发生过抢占的时候，就可以说明是当前没有在进行的读操作了，写操作就可以顺利的继续执行。
            即只要当前cpu发生上下文切换

        > 开销很大
            1> 读锁关闭当前cpu抢占
            2> 内核中有一个rcu_gp_kthread线程，专门用来发起宽限期和收集各个CPU的抢占信息，在满足条件后通知写操作继续。由于RCU是全局的，对不同资源的写操作有可能同时在产生，这个时候在一个宽限期结束的时候，会同时唤醒所有在等待的写操作。
            3> 也正是因为RCU可以算是一个超大力度的内核锁，任何的写请求都要等待整个系统的读请求完成，所以RCU锁对写操作时非常不友好的。这也是RCU锁用在多读少写的情况。

        > RCU是一种设计模式
            删除链表元素为例
            1> 遍历该链表得到指向元素 B 的指针
            2> 修改元素 B 的前后指向，A->next->C, A<-prep<-C        
            3> 修改指针指向是原子性的，而且元素B并没有更改。期间读者访问不需要同步
            4> 写者完成这些操作后注册一个回调函数(grace period 之后删除元素 B)
            5> 垃圾收集器在检测到所有的CPU不在引用该链表后，即所有的 CPU 已经经历了 quiescent state,grace period 已经过去后，就调用刚才写者注册的回调函数删除了元素 B。

    2) 实现机制
                                            reader0, reader1, reader2
                                               ↓        ↓        ↓
                        +------------->RCU projected data(old version) <------reclamation
                        ↑         | 
        RCU projected pointer     | removal 
                        ↓         ↓      
                        +------------->RCU projected data(new version)
                                             ↑              ↑
                                          reader3         reader4                        
        1> removal
            write分配一个new version的共享数据进行数据更新，更新完毕后将RCU protected pointer指向新版本的数据。一旦把RCU protected pointer指向的新的数据，也就意味着将其推向前台，公布与众（reader都是通过pointer访问数据的）。通过这样的操作，原来read 0、1、2对共享数据的reference被移除了（对于新版本的受RCU保护的数据而言），它们都是在旧版本的RCU protected data上进行数据访问。
        2> reclamation
            共享数据不能有两个版本，因此一定要在适当的时机去回收旧版本的数据。当然，不能太着急，不能reader线程还访问着old version的数据的时候就强行回收，这样会让reader crash的。reclamation必须发生在所有的访问旧版本数据的那些reader离开临界区之后再回收，而这段等待的时间被称为grace period。
        顺便说明一下，reclamation并不需要等待read3和4，因为write端的为RCU protected pointer赋值的语句是原子的，乱入的reader线程要么看到的是旧的数据，要么是新的数据。对于read3和4，它们访问的是新的共享数据，因此不会reference旧的数据，因此reclamation不需要等待read3和4离开临界区。

    3) API
        > reader
            > rcu_read_lock
                用来标识RCU read side临界区的开始
                //对于读者，RCU 仅需要抢占失效，因此获得读锁和释放读锁分别定义为
                #define rcu_read_lock()         preempt_disable()
                #define rcu_read_unlock()       preempt_enable()
            
            > rcu_dereference
                该接口用来获取RCU protected pointer, reader要访问RCU保护的共享数据，当然要获取RCU protected pointer，然后通过该指针进行dereference的操作
                也是读内存屏障

            > rcu_read_unlock
                用来标识reader离开RCU read side临界区

        > writer
            > rcu_assign_pointer
                该接口被writer用来进行removal的操作。在writer完成新版本数据分配和更新之后，调用这个接口可以让RCU protected pointer指向RCU protected data(new version)。
                写内存屏障
            
            > synchronize_rcu
                writer端的操作可以是同步的，也就是说，完成更新操作之后，可以调用该接口函数等待所有在旧版本数据上的reader线程离开临界区，一旦从该函数返回，说明旧的共享数据没有任何引用了，可以直接进行reclaimation的操作。

            > call_rcu
                某些情况下（例如在softirq context中），writer无法阻塞，这时候可以调用call_rcu接口函数，该函数仅仅是注册了callback就直接返回了，在适当的时机会调用callback函数，完成reclaimation的操作。这样的场景其实是分开removal和reclaimation的操作在两个不同的线程中：updater和reclaimer。

    4) 实例
        > 普通应用
            struct foo{
                int a;
                char b;
                long c;
            };
            DEFINE_SPINLOCK(foo_mutex);
            struct foo *glob_foo;    

            void foo_read(void){
                rcu_read_lock()

                //读屏障
                //foo *fp = glob_foo;
                foo *fp = rcu_dereference(glob_foo);    //确保fp = glob_foo
                
                if (fp != NULL) {
                    do_somthing(fp->a, fp->b, fp->c);
                }
                rcu_read_lock()
            }

            void foo_write(struct foo *new_foo) {
                spin_lock(&foo_mutex);
                foo *old_foo = glob_foo;
                new_foo->a = 1;
                new_foo->b = 'b';
                new_foo->c = 100;

                //由于存在编译器优化或cpu优化导致的乱序，要用写内存屏障
                //glob_foo = new_foo; 
                rcu_assign_pointer(glob_foo, new_foo);      //确保

                spin_unlock(&foo_mutex);
                synchronize_rcu();
                kfree(old_foo);
            }

        > 链表操作的RCU版本
            
```

### 抢占与同步
```
1、为什么需要加锁
    内核是抢占性的（无论是多处理器还是单处理器），一个与运行在临界区中的内核进程可以停下来以便让优先级更高的进程执行。所以内核抢占代码使用自旋锁作为非抢占区域标记
    自旋锁禁止内核和中断抢占

2、不需要加锁
    如果数据对处理器是唯一的，仅仅禁止中断就可以了，不需要加锁(类似伪并发访问)


3、抢占相关API
    //增加抢占计数器，从而禁止内核抢占
    preempt_disable()   
    //激活内核抢占，检查和执行被挂起的需调度的任务
    preempt_enable()   
    //激活内核抢占，但是不会检查和执行被挂起的需调度的任务
    preempt_enable_no_resched()   
    //返回抢占计数
    preempt_count()
    //根据当前的cpu编号，索引cpu变量
    int cpu
    cpu = get_cpu()     //禁止内核抢占，并获得当前cpu号
    //对数据进行操作
    put_cpu()           //激活内核抢占


```

### 内存屏障
```
https://www.jianshu.com/p/64240319ed60
http://ifeve.com/linux-memory-barriers/
http://ifeve.com/memory-barriers-or-fences/
https://zhuanlan.zhihu.com/p/43526907

1、原子操作，内存屏障，锁
    几乎所有的锁都使用了内存屏障
    所有的同步操作最基础的理论就是原子操作
    内存屏障并不是锁，而锁是使用了内存屏障实现的一种用户层的同步处理方式

2、为什么需要内存屏障
    内存的排序既可能发生在编译器编译期间，也可能发生在 CPU 指令执行期间
    多线程环境下，指令的乱序执行会造成无法预测的行为
    X86和ARM的memory ordering就截然不同
    Memory Barrier(内存屏障)来解决此问题
    c++提供了6种标准的memory order实现
    代码顺序并不是真正的执行顺序，只要有空间提高性能，CPU和编译器可以进行各种优化
    // cpu乱序执行
        在一个固定长度的执行队列中，寻找可以同时执行的指令。这个过程只需考虑指令间是否有依赖关系，不需要理解程序的意图
    // 编译器重排
        比处理器的范围更大，能在很大范围内进行代码分析,从而做出更优的策略,充分利用处理器的乱序执行功能

3、什么地方需要内存屏障
    在正常操作下，一个单线程代码片段中内存操作重排序一般不会产生问题，仍然可以正常工作，即使是在一个SMP内核系统中也是如此。但是，下面四种场景下，重新排序可能会引发问题：
    > 多处理器间的交互
    > 原子操作
    > 设备访问
    > 中断

4、内存屏障
    (1) 可见性与重排序
        1) 可见性
            cpu不同级别的Cache缓存，可以提高性能，但是多核时代会导致一致性问题
            例如：
                Core0与Core1命中了内存中的同一个地址，那么各自的L1 Cache会缓存同一份数据的副本
                Core0修改自己的L1 Cache，而Core1的L1 Cache的值没变
        2) 重排序
            > 真·重排序
                编译器、底层硬件（CPU等）出于"优化"的目的，按照某种规则将指令重新排序
                指令被发送到一个指令序列（也称执行缓冲区或者保留站）中。指令将在序列中等待，直到它的数据运算对象是可以获取的。然后被送到执行单元
            > 伪·重排序
                由于缓存同步顺序等问题，看起来指令被重排序了
            > 来源
                编译器编译时的优化 真·重排序
                处理器执行时的乱序优化 真·重排序
                缓存同步顺序（导致可见性问题）伪·重排序


    (2) 什么是内存屏障
        一个系统中，CPU和其它硬件可以使用各种技巧来提高性能，包括内存操作的重排、延迟、合并、预取、推测执行分支以及各种类型的缓存
        内存屏障是用来禁用或抑制这些技巧的，使代码稳健地控制多个CPU和(或)设备的交互
        不同的CPU架构上内存屏障的实现非常不一样，内存屏障是cpu技术

    (3) 内存屏障功能
        1) 屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性
        2) 实现内存数据可见性，确保内存数据会同步到CPU缓存子系统
        // 注意
            "可见性"可以认为是弱的"一致性"(弱一致)，只保证用户见到的数据是一致的，但不保证任意时刻，存储的数据都是一致的(强一致)
            下文会讨论"缓存可见性"问题，部分文章也会称为"缓存一致性"问题

    (4) 重排序场景
        1) 编译器编译时的优化
            volatile禁用编译器优化
            解决了编译器重排
        2) 处理器执行时的乱序优化
            特殊的指令
            解决了cpu重排
        3) 缓存同步顺序(导致可见性问题)
            MESI协议，解决CPU缓存层面的问题
            解决了内存可见性
        // 注意
            C++中voldatile等于插入编译器级别屏障，因此并不能阻止CPU硬件级别导致的重排
            C++11中volatile语义没有任何变化，不过提供了std::atomic工具可以真正实现原子操作，而且默认加入了内存屏障

    (5) 内存屏障
        1) 屏障类型
            > LoadLoad Barriers
                指令示例: Load1;LoadLoad;Load2	
                说明: 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作
            > StoreStore Barriers
                指令示例: Store1;StoreStore;Store2
                说明: 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作
            > LoadStore Barriers
                指令示例: Load1;LoadStore;Store2
                说明: 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作
            > StoreLoad Barriers
                指令示例: Store1;StoreLoad;Load2	
                说明: 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作。它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令
                注意：
                    该屏障同时具备其他三个屏障的效果，因此也称之为全能屏障（mfence），是目前大多数处理器所支持的；但是相对其他屏障，该屏障的开销相对昂贵。然而，除了mfence，不同的CPU架构对内存屏障的实现方式与实现程度非常不一样
        2) x86内存屏障(指令)
            > Store Barrier
                sfence指令，相当于StoreStore Barriers
                强制所有在sfence指令之前的store指令，都在该sfence指令执行之前被执行，发送缓存失效信号，并把store buffer中的数据刷出到CPU的L1 Cache中；所有在sfence指令之后的store指令，都在该sfence指令执行之后被执行。即，禁止对sfence指令前后store指令的重排序跨越sfence指令，使所有Store Barrier之前发生的内存更新都是可见的
            > Load Barrier
                lfence指令，相当于LoadLoad Barriers  
                强制所有在lfence指令之后的load指令，都在该lfence指令执行之后被执行，并且一直等到load buffer被该CPU读完才能执行之后的load指令（发现缓存失效后发起的刷入）。即，禁止对lfence指令前后load指令的重排序跨越lfence指令，配合Store Barrier，使所有Store Barrier之前发生的内存更新，对Load Barrier之后的load操作都是可见的
            > Full Barrier
                mfence指令，相当于StoreLoad Barriers
                mfence指令综合了sfence指令与lfence指令的作用，强制所有在mfence指令之前的store/load指令，都在该mfence指令执行之前被执行；所有在mfence指令之后的store/load指令，都在该mfence指令执行之后被执行。即，禁止对mfence指令前后store/load指令的重排序跨越mfence指令，使所有Full Barrier之前发生的操作，对所有Full Barrier之后的操作都是可见的

```

### memory order
```

详见《cpu体系结构的cpu乱序执行、编译器重排》
1) 关键概念
    > 同步原语
        所有的同步原语都起优化和内存屏障的作用
    
    > 优化屏障
        编译器对代码的优化
        asm volatile("":::"memory")
        
        volatile关键字禁止编译器把asm指令与程序其他指令重新组合, memory关键字强制编译器假定RAM中所有的内存单元已经被汇编指令修改
        因此，编译器不能使用cpu寄存器中的内存单元值来优化asm指令，需要重新存取内存的数据
        注意：编译屏障并不直接影响CPU，CPU依然可以按照它所希望的顺序进行重排序
    > 内存屏障
        cpu确保汇编指令的顺序
        相关指令
        > 对I/O端口进行操作的所有指令
        > lock前缀的所有指令
        > 写控制寄存器、系统寄存器或调试寄存器的指令
        > 一些汇编指令lfence(读) sfence(写) mfence(读写)
    2) API
        > rmb
            rmb()提供一个读内存的屏障。确保跨域rmb()的载入动作不会发生重排序
            rmb()之前的载入操作不会排在该调用之后，同理rmb()之后的载入操作不会排在该调用之前
        > wmb
            wmb()提供一个写内存的屏障。确保跨域wmb()的写入动作不会发生重排序
            wmb()之前的写操作不会排在该调用之后，同理wmb()之后的写操作不会排在该调用之前
        > mb
            mb方法提供了读屏障和写屏障
        > 示例
            a的初始值为1，b的初始值为2
            线程1           线程2    
            a = 3           --
            mb()            --
            b = 4           c = b
            --              rmb()
            --              d = a
            其中mb()确保了a和b按照预定的顺序写入，rmb()确保c和d按照预定的顺序读取

```

### spin lock的优化
```
https://zhuanlan.zhihu.com/p/84617791?utm_source=qq&utm_medium=social&utm_oi=555400798499188736


```

