> 致敬Lamport大师

### 资料
```
《分布式系统设计实践》
《大型网站技术架构：核心原理与案例分析》
《大规模分布式存储系统:原理解析与架构实战》
《设计数据密集型应用》https://github.com/Vonng/DDIA
《分布式架构知识体系》https://zhuanlan.zhihu.com/p/87157382
《两万字深度介绍分布式系统原理》https://zhuanlan.zhihu.com/p/100283343
《现在主流开源分布式系统架构都有哪些？》https://www.zhihu.com/question/19832447
```

### 分布式特点
```
分布性
    分布式系统中的多台计算机都会在空间上随意分布

对等性
    分布式系统没有主/从之分，即没有控制整个系统的主机，也没有被控制的从机，所有计算机都是对等的
    副本是分布式常见概念之一，指分布式对数据和服务提供一种冗余的方式
    > 数据副本指在不同节点上持久化同一份数据，防止某一节点丢失时，可以提供丢失数据的副本供给的高可用手段
    > 服务副本指多个节点运行相同的服务，用于处理外部请求，提供并发处理

并发行
    分布式中的多个节点会并发请求共享资源(分布式存储)，准确并高效的协调分布式并发操作非常重要

全局时钟
    不同节点的时钟不一样。需要分布式系统的时钟和顺序

故障
    故障随时会发生
```

### 一致性
```
分布式系统的事务处理与数据一致性

1、ACID
    事务是由一系列对数据进行访问与更新的操作所组成的一个程序执行逻辑单元，特指数据库事务
    当多个程序并发访问数据时，事务可以提供一个隔离方法，防止相互干扰
    事务具有四个特性：Atomicity（原子性）、Consistency（一致性）、Isolation（隔离性）、Durability（持久性）
    > Atomicity
        事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。
        事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。
    > Consistency
        事务开始前和结束后，数据库的完整性约束没有被破坏
        比如A向B转账，不可能A扣了钱，B却没收到。
    > Isolation
        同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰
        比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账
        隔离级别    脏读    可重复度    幻读
        未授权读取  存在    不可以      存在
        授权读取    不存在  不可以      存在
        可重复读取  不存在  可以        存在
        串行化      不存在  可以        不存在
    > Durability
        事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚
    
2、分布式事务
    在分布式领域，为了确保业务的完整与正确性，分布式事务无法避免，而且非常复杂
    
3、CAP
    在分布式系统中很难做到ACID，所以提出了CAP
    CAP理论主张基于网络的数据共享系统，都最多只能拥有以下三条中的两条
    Consistency（一致性）、Available（可用性）、Partition Tolerance (分区容错性)
    > 一致性
        指数据多个副本之间是否能够保持一致
        即更新操作成功并返回客户端后，所有节点在同一时间的数据完全一致，这就是分布式的一致性。一致性的问题在并发系统中不可避免，对于客户端来说，一致性指的是并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致
    > 可用性
        指系统提供的服务必须一直处于可用的状态，强调每一个操作总是能够在"有限时间内" "返回结果"
        好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况
    > 分区容错性
        即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务
        分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，对于用户而言并没有什么体验上的影响
        
    CAP三个特性只能满足其中两个，那么取舍的策略就共有三种：
    > CA without P (违背分布式)
        如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的
    > CP without A
        如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库
    > AP wihtout C
        要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞
    
4、BASE
    基于CAP理论发展而来，核心思想是即便不能达到强一致性，但可以根据应用特点采用适当的方式达到最终一致性
    BasicallyAvailable（基本可用）、Soft State（软状态）、Eventual consistent（最终一致性）
    > Basically Available
        假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言
        响应时间上的损失、功能上的损失
    > Soft state
        硬状态是多个节点的数据副本都是一致的
        软状态允许系统在多个不同节点的数据副本存在数据延时
    > Eventually consistent
        保证数据最终一致性

```

### 一致性协议
```
https://zhuanlan.zhihu.com/p/31780743
https://www.cnblogs.com/linbingdong/p/6253479.html

为了需要在系统可用性与数据一致性之间进行反复权衡，于是产生了一致性协议

1、2PC(二阶段提交)
    包含协调者和参与者
    协调者负责调度参与者的行为，并最终决定这些参与者是否把事务真正进行提交
    绝大多数关系型数据库采用二阶段提交协议来完成分布式事务处理
    (1) 协议
        1) 阶段一(提交事务请求)
            协调者组织参与者对事物投票表态阶段
            1> 事务询问
                协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待参与者响应
            2> 执行事务
                各参与者执行事务操作，并记录undo和redo信息
            3> 反馈响应
                事务执行成功的参与者反馈给协调者yes响应，表示事务可以执行。相反不能成功执行的参与者返给协调者no响应，表示事务不可以执行
        2) 阶段二(执行事务提交)
            参与者投票表明是否要继续执行事务提交操作，分为两种情况
            1> 执行事务提交
                假如协调者从所有参与者获得的反馈都是yes，则会执行事务提交
                协调者向所有参与者节点发出commit请求
                1> 事务提交
                    参与者收到commit请求后，会正式执行事务提交操作，然后释放事务执行期间占用的资源
                2> 反馈提交结果
                    参与者完成事务提交后，向协调者发送ACk消息
                3> 完成事务
                    协调者收到所有参与者的ACK后，完成事务
                
            2> 中断事务
                假如任何一个参与者反馈no响应或等待超时后，则会中断事务
                1> 发送回滚请求
                    协调者向所有节点发出Rollback请求
                2> 事务回滚
                    参与者收到Rollback后，会利用undo执行事务回滚，完成回滚后释放资源
                3> 反馈事务回滚结果
                    参与者完成回滚后，向协调者发送ACK消息
                4> 中断事务
                    协调者收到所有参与者的ACK消息后，完成事务中断

    (2) 优缺点
        虽然上述协议原理简单，实现方便，但是存在以下缺点
        1) 同步阻塞
            二阶段提交过程中，所有参与该事务的操作都处于阻塞状态。各个参与者会存在等待其他参与者的情况，严重影响性能
        2) 单点问题
            一旦协调者出现问题，整个系统无法运行
        3) 数据不一致
            二阶段提交过程中，因为一些故障导致一部分参与者收到commit请求，而另一部分没有收到commit请求，会出现数据不一致的情况
        4) 太过保守
            没有容错机制，任意一个节点失败会导致整个事务失败

2、3PC
    (1) 协议
        1) CanCommit
            1> 事务询问
                协调者向所有参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务提交操作，并等待响应
            2> 参与者反馈响应
                参与者收到canCommit请求后，如果认为自己执行事务提交操作，则返回yes响应，并进入预备状态，否则反馈no
        2) PreCommit
            协调者会根据参与者的反馈情况来决定事务的操作，存在两种可能
            1> 执行事务预提交
                假如所有的参与者都返回yes响应，则执行事务预提交
                1> 发出预提交请求
                    协调者向所有参与者发出preCommit请求，并进入prepare阶段
                2> 事务预提交
                    参与者收到preCommit请求后执行事务操作，并记录undo和redo
                3> 反馈事务执行响应
                    如果参与者成功执行了事务，就会反馈协调者ACK响应，同时等待最终指令(提交或终止)
            2> 中断事务
                假如任何一个参与者返回no响应或等待超时，则就会中断事务
                1> 发送中断请求
                    协调者向所有参与者发送abort请求
                2> 中断事务
                    参与者收到abort请求或者等待请求超时，都会出现中断事务
        3) doCommit
            该阶段进行真正的事务提交，存在两种可能
            1> 执行提交
                1> 发送提交请求
                    假如协调者处于正常状态，并受到所有参与者的ACK响应，那么将状态从预提交转换为提交，并向所有参与者发送doCommit请求
                2> 事务提交
                    参与者收到doCommit请求后，会正式执行事务提交操作，然后释放事务执行期间占用的资源
                3> 反馈提交结果
                    参与者完成事务提交后，向协调者发送ACk消息
                4> 完成事务
                    协调者收到所有参与者的ACK后，完成事务
            2> 中断事务
                这一阶段，假如协调者处于正常状态，并且任意一个参与者返回no响应或者等待超时，就会进入中断事务
                1> 发送中断请求
                    协调者向所有参与者发出abort请求
                2> 事务回滚
                    参与者收到abort后，会利用阶段二记录的undo执行回滚操作，然后释放事务执行期间占用的资源
                3> 反馈事务回滚结果
                    参与者完成回滚后，向协调者发送ACK消息
                4> 中断事务
                    协调者收到所有参与者的ACK消息后，完成事务中断

            注意：一旦进入三阶段，会出现两种状况
            1> 协调者出现问题
            2> 协调者和参与者之间网络出现故障
            上述情况会出现参与者无法收到来自协调者的doCommit或abort请求
            对于这样情况，参与者都会在等待超时后，继续进行事务提交
    (2) 优缺点
        1) 优点
            与二阶段相比最大优点是降低参与者的阻塞范围，并且在出现单点故障后继续达成一致
        2) 缺点
            参与者接收到preCommit后，如果网络出现分区，协调者和参与者无法进行正常通信，这是参与者依然会进行事务提交，必然导致数据不一致

3、Paxos
    Paxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。
    Paxos算法解决的问题正是分布式一致性问题，即一个分布式系统中的各个进程如何就某个值（决议）达成一致
    (1) 三个角色
        Proposer: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。
        Acceptor：参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。
        Learner：不参与决策，从Proposers/Acceptors学习最新达成一致的提案（Value）。
    (2) Proposer与Acceptor
        1) Proposer生成提案
            1> Prepare请求
                Proposer生成一个新的提案编号N，然后向某个Acceptor集合的成员发送'编号为N的Prepare请求'，要求集合中的成员做出以下回应(承诺诺)
                > 不再批准任何编号小于N的提案
                > 如果Acceptor已经接受过提案，那么就向Proposer反馈当前已批准编号小于N的最大编号的提案
            2> Accept请求
                > 确定提案
                    如果Proposer收到了半数以上的Acceptor的响应，那么它就可以生成编号为N，value值为V的提案。这里的V是所有的响应中编号最大的提案的Value，N为当前Accept提案编号。如果半数以上的响应中都没有任何提案，那么此时V就可以由Proposer自己生成
                > 发送提案               
                    在此Proposer确定提案后，然后再将此提案(N, V)发给某Acceptor集合
        2) Acceptor批准提案
            Acceptor处理逻辑：一个Acceptor只接受编号大于已响应过编号的请求
            Acceptor会收到来自Proposer的两种请求Prepare和Accept
            1> 响应Prepare(N)请求，做出是否响应此编号
                如果编号N小于等于之前Acceptor承诺的编号，那么拒绝此响应。否则接受响应，并返回已批准的最大编号的提案(如果有)
            2> 响应Accept(N, V)请求，做出是否批准此提案
                如果编号N小于之前Acceptor承诺的编号，那么拒绝此提案。否则接受此提案，并且承诺不接受编号小于等于的N的响应
        
    (3) 算法两个阶段描述
        两个阶段可能轮回交替
        1) 阶段一
            1> Prepare
                Proposer生成全局唯一且递增的编号N，然后向所有Acceptor发送编号为N的Prepare请求(这里无需携带内容)
            2> Promise
                Acceptor收到编号为N的Prepare请求，做出"两个承诺，一个应答"
                两个承诺
                1> 不再接受任何编号小于等于N的Prepare请求
                2> 不再接受任何编号小于N的Propose提案
                一个应答
                如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它批准过的编号最大的提案(注意此处是批准的提案，不是承诺的提案编号，说明已经历了Accept过程)作为响应反馈给Proposer，如果没有批准过提案，则返回空值
                
        2) 阶段二
            1> Propose
                如果Proposer收到半数以上的Acceptor对于其发出编号N的Prepare请求做出了响应，然后从收到的提案中选择编号最大的提案valueMax，将自身的编号(注意不是最大编号)和此值，即(N, valueMax)发送给所有的Acceptor。如果响应中不包含任何提案，那么就填上任意值
            2> Accept
                Acceptor收到Propose(N, valueMax)请求后，只要该Acceptor尚未对编号大于N的Prepare请求做出响应，那么接受此提案(持久化，发送给learner)。否则拒绝此提案

        伪代码描述:

                      Proposer(N, V)                              Acceptor(ResN, AcceptN, AcceptV)

                   |  Prepare(N)全局唯一，递增 -+                 
                   |                           |               
                   |                           +----------------> def Prepare(N):
            step1  |                                                 if N <= ResN:
                   |                                                    不响应或return(err)
                   |                                                 if N > ResN:
                   |                                                    ResN = N
                   |                                    +--------       return (ok, AcceptN, AcceptV) 或 (ok, null, null)
                                                        |
                   |  if 收到超半数的ok响应 <------------+
                   |       V
                   |       if 响应有提案:
                   |          V = 响应中获得最大提案编号对应的值
                   |       else:
                   |          V = 自己定义
                   |       发起Accept(N, V)请求
                   |  else:
                   |       重新获取N
            step2  |       重新发起Prepare(N)请求
                   |               |
                   |               +--------------------------->  def Accept(N, V):
                   |                                                 if N >= ResN:
                   |                                                     AcceptN = N
                   |                                                     AcceptV = V
                   |                                                     ResN = N
                   |                                                     return (ok)
                   |                                                 else:
                   |               +---------------------------          return (err)
                   |               ↓
                   |  收到超半数响应ok，说明已接受提案
                   |  否则，没有接受提案，重新Prepare


    (4) 活锁
        假设有两个Proposer一次提出编号递增的提案，最终会陷入死循环(无法保证活性)
        > Proposer P1发出编号为M1的Prepare请求，收到过半ok响应。完成阶段一流程
        
        > Proposer P2发出编号为M2(M2>M1)的Prepare请求，也收到过半ok响应。也完成阶段一流程，此时Acceptor承诺不再接受编号小于M2的提案

        > P1进入第二阶段，发出Accept(M1)请求，Acceptor拒绝请求(M1<M2)，P1重新发出编号M3(M3>M2)的Prepare请求，Acceptor收到请求后承诺不再接受编号小于M3的提案

        > P2进入的二阶段，发出Accept(M2)请求，Acceptor拒绝请求(M2<M3)，P2又重新Prepare请求

        > 进入死循环

        解决方案：选取一个主Proposer，只有主Proposer才能提出议案(Prepare)


    (5) Learner方案
        Learner学习（获取）被选定的value有如下三种方案
        1) Acceptor接受一个提案，然后发送给所有Learner
            优点：Learner能尽快的获取被选定的提案
            缺点：通信次数高(m*n)

        2) Acceptor接受一个提案，然后发送给主Learner，主Learner再通知其他Learner
            优点：通信次数少(m+n-1)
            缺点：主Learner出现故障

        3) Acceptor接受一个提案，然后发送给部分Learner，部分Learner再通知其他Learner
            优点：可靠性好
            缺点：太复杂
```

### paxos的应用
```
Chubby
1、系统结构
    (1) Master
        一个Chubby集群(通常5台服务器)，采用Paxos选择一台master，master租期期间不会有其他服务器成为master，master会不断续租，直到master出现故障，新一轮选举，产生新master
    (2) 数据存储方式
        集群中每个服务器都维护一份数据库副本，但只有master才有写数据库的权限，其他服务器使用Paxos协议从master服务器上同步数据
    (3) 定位Master
        请求DNS服务器获得所有Chubby服务器列表，轮询该列表。如果是非Master服务器则会返回Master地址
    (4) 请求的发送
        客户端会将所有请求发给Master。对于写请求，Master会采用Paxos将其广播给集群中的所有服务器，在收到过半响应后，在返回给客户端；对于读请求，Master不会进行广播处理，则直接返回给客户
    (5) 服务器故障处理
        master故障会重新选举
        非master故障，整个集群不会停止，此崩溃服务器会在恢复后自动加入Chubby集群中去
        新加入的服务器，需要先同步Chubby最新数据库，更新DNS列表，然后加入到正常的Paxos运作流程中
    (6) 服务器地址变更
        在Chubby运行过程中，Master会周期的轮询DNS列表。当感知到服务器地址列表变更时，Master会将集群数据库中的地址列表作相应的变更，然后其他服务器通过复制的方式获得最新的服务器地址列表     

2、几个关键的问题
    (1) 锁
        > 分布式锁错乱
            一个客户C1获取到互斥锁L1，然后发出请求R，但是没有到达服务器。另一个用户C2获取到互斥锁L2，也发出请求，并成功应用到服务器上。不幸的是，C1客户的请求经过一波三折到达了服务器，有可能会更改之前C2的数据
        > 锁序列器
            锁序列器可以解决此问题，任何时候请求的锁会带有锁的名字、锁模式(读、写)、锁序号。当带有锁的请求到达服务器时，服务器会先检查锁序号是否有效，以及检查是否处于恰当的锁模式来决定是否拒绝此请求
    (2) 客户端如何获得服务端状态
        客户端获得Chubby服务端状态不是通过轮询来获得的，而是通过注册事件通知，常见事件如下：
        文件内容变更
        节点新增删除
        Master转移
    (3) 缓存
        > 为什么需要
            为了避免客户端频繁的请求服务端，客户端会存在缓存来存储相关信息（文件内容和元数据信息）。但是会带来系统复杂性，最主要就是缓存一致性
        > 缓存一致性
            > 原理
                通过租期机制来保存缓存一致性
                Master通过向每个客户端发送过期信息来保证客户端数据一致性，会导致客户端要么从缓存中得到一致性数据，要么访问出错
            > 解决方法
                > 客户端缓存会存在一个租期，一旦到期需要向服务器续订租期来维护一致性
                > 当要修改数据时，Chubby服务端会阻塞该修改操作，然后Master向'所有'缓存该数据的客户端发送缓存过期信号使其失效。等到Master收到所有客户端的应答时(客户端允许缓存过期或要求更新缓存)，再继续进行之前的修改操作
                总之Chubby是通过强一致性来解决此问题的。尽管性能开销比较大，但是很稳
    (4) KeepAlive
        Chubby客户端与服务端的通信都是基于TCP来进行操作的


        
    (4)




```


























### 基础知识
```
分层：服务层 -> 中间件 -> 操作系统 -> 硬件

中间件
    中间件在分布式系统中的地位和角色为了使种类各异的计算机和网络都呈现为单个的系统
    分布式系统常常通过一个软件层组织起来
    该层在逻辑上位于由用户和应用程序组成的高层与由操作系统组成的低层之间，这样的分布式系统又称为中间件
    分类
        分布式对象和组件
        消息队列        
        web服务

一致性

通信
    通信实体
        对象
        组件
        web服务
    通信泛型(如何通信)
        进程间通信
        远程调用(RPC)
        间接通信(组通信、发布-订阅、消息队列、元祖空间、分布式共享内存)


分布式对象




流量调度

负载均衡

分布式文件系统

时间与顺序
    Lamport 时钟

协调和同步

分布式事务

复制

```



### 场景分类
```

```




### 基础理论
```
1、SOA到MSA的进化

1、节点与网络

2、时间与顺序

3、一致性理论
    

4、一致性算法
    (1) 2PC
    (2) 3PC
    (3) Paxos
    (4) Raft
```

### 系统分类
```
http://book.mixu.net/distsys/
https://www.zhihu.com/question/23645117

1、分布式存储系统 
    (1) 相关算法
        Paxos, CAP, Consistent Hash, Timing (时钟), 2PC, 3PC
    (2) 分类
        结构化存储
            事务处理系统或者关系型数据库
        非结构化存储 
            分布式文件系统，例如HDFS
            GFS主要思想：master管理、chunks存储并保存多个副本、自动容错恢复
            吞吐率都非常好，适合大文件。无法支持随机访问。
        半结构化存储 
            为了解决结非构化存储系统随机访问性能差的问题
            Nosql、对象存储
            包括Bigtable、Dynamo、HBase
        In-memory 存储
            Redis、memcahed
        NewSQL
            黑科技

2、分布式计算系统
    (1) 相关算法
        MapReduce, 核心就是容错
        传统基于msg的系统 
    (2) 分类     
        MapReduce-like 系统 
        图计算系统
        基于状态（state）的系统 
        Streaming 系统
        
3、分布式管理系统

```

### 场景分类
```
https://zhuanlan.zhihu.com/p/57372027

1、文件系统
    GlusterFS（NAS NFS）、HDFS（hadoop）、ceph（虚机块存储）、swift（restful对象存储）

2、数据库
    也属于文件系统，主数据增加了事务，检索，擦除等高级特性，所以复杂度又增加了，既要考虑数据一致性也得保证足够的性能
    列式存储：Hbase
    文档存储：Elasticsearch，MongoDB
    KV类型：Redis
    关系型：mysql,Spanner

3、计算
    分布式计算系统构建在分布式存储的基础上，充分发挥分布式系统的数据冗余灾备，多副本高效获取数据的特性，进而并行计算，把原本需要长时间计算的任务拆分成多个任务并行处理，从而提高了计算效率
    离线：Hadoop
    实时：Spark
    流式：Storm，Flink/Blink

4、缓存
    提升性能，分布式缓存系统提供了热点数据的随机访问机制，大大了提升了访问时间，但是带来的问题是如何保证数据的一致性，引入分布式锁来解决这个问题
    持久化：Redis
    非持久化：Memcache

5、消息
    分布式消息队列系统是消除异步带来一系列的复杂步骤的一大利器，多线程高并发场景先我们常常要谨慎的去设计业务代码，来保证多线程并发情况下不出现资源竞争导致的死锁问题。而消息队列以一种延迟消费的模式将异步任务都存到队列，然后再逐个消化。
    Kafka
    RabbitMQ
    RocketMQ
    ActiveMQ

6、监控协调
    分布式系统从单机到集群的形态发展，复杂度也大大提高，所以对整个系统的监控也是必不可少
    Zookeeper（paxos的实现）: ZooKeeper 为分布式应用提供了高效可靠的分布式协调服务，提供了统一命名服务、配置管理和分布式锁等分布式的基础服务

7、应用
    分布式系统的核心模块就是在应用如何处理业务逻辑，应用直接的调用依赖于特定的协议来通信，有基于 RPC 协议的，也有基于通用的 HTTP 协议
    HSF
    Dubbo

8、日志
    日志采集：flume
    日志存储：ElasticSearch/Solr，SLS
    日志定位：Zipkin

```



### 模块分类
```
1、分布式系统的前端构造
    (1) Web框架
        MVC
    (2) 反向代理
        Nginx　
    (3) 负载均衡
        DNS负载均衡
        硬件负载均衡
        软件负载均衡

2、分布式中间件
    (1) 分布式同步服务中间件
        一致性协议、ZooKeeper　
    (2)	分布式关系型数据库访问中间件
        MySQL、Cobar
    (3) 分布式服务调用中间件
        Dubbo、gRPC(以及一些rpc高性能框架)
    (3) 分布式消息服务中间件				
        Kafka
    (4) 分布式跟踪服务中间件
        日志 Zipkin

3、分布式存储
    (1) 分布式文件系统
        HDFS、Ceph
    (2) 分布式对象存储
        HDFS+HBase（Base存元数据，利用HDFS的Append功能将小文件合并成大文件）
    (3) 分布式Nosql
        > k-value Nosql
            Redis
        > 列 Nosql
            HBase
        > 文档 Nosql
            Mongodb
        > 图 Nosql
            Neo4j
        > 时间序列 Nosql
            influxDb
        > Newsql


```

### 工程应用
```
1、资源调度
    弹性伸缩：在容器化技术的支撑下，应用扩容，机器下线，机器置换
    网络管理
    故障快照
    现场保留：内存分布，线程数等资源现象的保存
    调试接入：采用字节码技术无需入侵业务代码，可以供生产环境现场日志打点调试

2、流量调度
    负载均衡
    网关设计
    流量管理
        请求校验：非法请求拦截，清洗
        数据缓存：CDN
    流控控制
        真实流量我们采用不同的算法来分流请求
        流量分配
        流量限制：防止系统出现雪崩，预估系统的流量上限，设定阈值

3、服务调度
    流量做好了调度管理后，剩下的就是服务自身的健壮性了

4、数据调度
    状态转移：分离状态至全局存储，请求转换为无状态流量，比如我们通常会将登陆信息缓存至全局redis中间件，而不需要在多个应用中去冗余用户的登陆数据
    分库分表：数据横向扩展
    分片分区：多副本冗余

5、自动化运维
6、容错处理
7、全栈监控
8、故障恢复
9、性能调优
    分布式锁
    高并发
    异步
```

### 分布式基本问题
```
(1) 分布式时钟, 又叫Lamport Clock
(2) 一致性问题，分布式系统的几种一致性，以及具体系统实现上的权衡
(3) 容错性分布式系统的协议以及实现方式，伟大的PAXOS 
```

### 分布式架构
```
https://zhuanlan.zhihu.com/p/74082768

```