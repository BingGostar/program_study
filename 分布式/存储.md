### 数据库存储引擎
```
1、哈希存储引擎(key-value)
	Bitcask是一个基于哈希表结构的键值存储系统，它仅支持追加操作
	支持增、删、改，以及随机读取；不支持顺序扫描；写操作只追加而不修改老的数据
	1) 数据结构
		> 文件
			活跃数据文件和老数据文件
			数据是一条一条的写入操作
			每一条记录的数据项分别为主键、value、主键长度、value、时间戳以及crc校验值
		> 哈希表
			内存中采用基于哈希表的索引数据结构，通过主键快速地定位到value的位置
			哈希表结构中的每一项包含了三个用于定位数据的信息，分别是文件编号（file id），value在文件中的位置（value_pos），value长度（value_sz）
		写入时
			首先将Key-Value记录追加到活跃数据文件的末尾
			接着更新内存哈希表
		因此，每个写操作总共需要进行一次顺序的磁盘写入和一次内存操作

	2) 定期合并
		> 记录删除或者更新后，原来的记录成为垃圾数据
		> 要定期执行合并（Compaction）操作以实现垃圾回收
		> 将所有老数据文件中的数据扫描一遍并生成新的数据文件
		> 对同一个key的多个操作以只保留最新一个的原则进行删除，每次合并后，新生成的数据文件就不再有冗余数据
	3) 快速恢复
		Bitcask通过索引文件来提高重建哈希表的速度	
		索引文件就是将内存中的哈希索引表转储到磁盘生成的结果文件

2、B-Tree
	B树存储引擎不仅支持随机读取，还支持范围扫描
	> 叶子节点保存每行的完整数据，非叶子节点保存索引信息
	> 每个节点中有序存储，数据库查询时需要从根节点开始二分查找直到叶子节点
	> 修改操作首先需要记录提交日志，接着修改内存中的B+树
	> 内存中的被修改过的页面超过一定的比率，后台线程会将这些页面刷到磁盘中持久化
	
3、LSM(key-value)
	[LSM 算法的原理]https://www.zhihu.com/question/19887265
	[levelDB Compaction]https://zhuanlan.zhihu.com/p/46718964
	[LSM-tree 基本原理及应用]https://cloud.tencent.com/developer/news/340271

	LSM树的优势在于有效地规避了磁盘随机写入问题，但读取时可能需要访问较多的磁盘文件
	(1) 存储结构
		k-v的数据结构是skiplist
		MemTable、Immutable MemTable、Current 文件、清单文件、日志文件、SSTable
		> MemTable是k-v结构，写入的值加入结构中(有序)
		> SSTable文件是内存中的数据不断进行Compaction操作后形成的
		> SSTable的所有文件是一种层级结构
		> 共有6层，0->5 逐渐增大，每层的SSTable是按照主键排序，每个文件有最小和最大键值

	(2) 写操作
		1) 数据首先会被写到log，保证持久性
		2) 然后写入memtable中，返回
		3）当 memtable 内存到达一定大小之后就会变成 immutable memtable
		4) 当到达一定的条件后，后台的 Compaction 线程会把 immutable memtable 刷到盘中 Level 0 中 sstable
		5) 当 level i 到一定条件后（某个 level 中的数据量或者 sstable 文件数据等）就会和 level i+1 中的 sstable 进行 Compaction，合并成 level i+1 的 sst 文件
	(3) 读操作
		1) 查询时首先会搜索内存中的MemTable，如果有则返回
		2) 如果没有读到，则搜索内存中的immutable Memtable，如果有则返回
		3) 如果没有读到，从新到老一层一层读取磁盘中的SSTable文件

	(4) Compaction
		为了提高读性能，执行Compaction操作来对已有的记录进行整理压缩，从而删除一些不再有效的记录，减少数据规模和文件数量
		分两种：minor compaction和major compaction
		1) minor compaction
			immutable memtable持久化为 SSTable 文件
		2) major compaction
			每个层级下有多个SSTable，当某个层级下的SSTable文件数目超过一定设置值后，levelDB会从这个层级中选择SSTable文件，将其和高一层级的SSTable文件合并
			> 目的
				均衡各个level的文件数量，提高read性能
				合并delete和update数据，释放磁盘空间
			> 细节
				在 Manual Compaction 中会指定的 begin 和 end，它将会一个level 一个level 的分次的Compact 所有level 中与begin 和 end 有重叠（overlap）的 sst 文件
```

### key-value数据结构
```
目前常用的key-value数据结构有三种：Hash表、红黑树、SkipList(跳表)

Hash表：插入、查找最快，为O(1)；如使用链表实现则可实现无锁；数据有序化需要显式的排序操作。
红黑树：插入、查找为O(logn)，但常数项较小；无锁实现的复杂性很高，一般需要加锁；数据天然有序。
SkipList：插入、查找为O(logn)，但常数项比红黑树要大；底层结构为链表，可无锁实现；数据天然有序。

skipList的实现比红黑树简单，但性能要低于红黑树

redis和levelDB用的是skipList
```

### 数据分类
```
(1) 结构化数据
    结构化的数据的存储和排列是很有规律的, 一般存取到数据库

(2) 半结构化数据
    json、xml，半结构化数据的扩展性是很好的

(3) 非结构化数据
    没有固定结构的数据。各种文档、图片、视频/音频等都属于非结构化数据
```

### 数据库存储分类(数据模型)
```
1、文件存储
	提供了POSIX标准的文件操作接口，但是POSIX标准适合单机文件系统，在分布式文件系统中，出于性能考虑，一般不会完全遵守这个标准
	非结构化的文件/对象模型，文件、图片、视频、文档等二进制数据
	(1) 分布式文件系统
    HDFS、GFS、ceph（虚机块存储）
		主要思想是master管理、chunks存储并保存多个副本、自动容错恢复
        吞吐率都非常好，适合大文件。无法支持随机访问
	(2) 分布式对象存储系统
		HDFS+HBase(HBase存元数据，利用HDFS的Append功能将小文件合并成大文件)
    	swift（restful对象存储）

2、关系型数据库
	每个关系是一个表格，由多个元组（行）构成，而每个元组又包含多个属性（列）
	关系名、属性名以及属性类型称作该关系的模式（schema）
	> SQL语言用于描述查询以及修改操作
		修改包含三条命令：INSERT、DELETE以及UPDATE，查询通常通过select-from-where语句来表达
	
	> SQL两个重要特性
		索引：减少SQL执行时扫描的数据量，提高读取性能
		事务：保证了多个操作并发执行时的ACID特性
	
3、键值模型数据库(非关系型)
	> 大量的NoSQL系统采用了键值模型
	> 每行记录由主键和值两个部分组成
	> 基于主键的操作
		Put：保存一个Key-Value对
		Get：读取一个Key-Value对
		Delete：删除一个Key-Value对
	> K-V模型过于简单，与关系模型不同，k-v(表格模型)一般不支持多表关联操作，事务操作支持也比较弱


4、sql和nosql
	(1) 不存在谁取代谁
		传统sql面对高数据量和高并发力不从心
		nosql具有良好扩展性、弱化设计范式、高数据量和高并发有一定的解决能力
		nosql缺少保持ACID、join和SQL等特性，不保证强一致性的(支持最终一致)
```

### 数据库存储分类(数据模型)
```

1、文件存储
	(1) 分布式文件系统
    HDFS、GFS、ceph（虚机块存储）
		主要思想是master管理、chunks存储并保存多个副本、自动容错恢复
        吞吐率都非常好，适合大文件。无法支持随机访问
	(2) 分布式对象存储系统
		HDFS+HBase(HBase存元数据，利用HDFS的Append功能将小文件合并成大文件)
    	swift（restful对象存储）

2、sql数据库
	针对结构化数据的存储
	适合OLTP场景
	事务处理系统或者关系型数据库
	MySQL和中间件

3、nosql数据库
	主要是键值数据库，针对结构化/半结构化数据
	适合OLAP场景
  	(1) Key-value
      	Redis、LevelDB(谷歌)、RocksDB(facebook)
  	(2) 列数据库
      	Hbase
    (3) 文档数据库
        MongoDB
    (4) 图 Nosql
        Neo4j
    (5) 时间序列
        influxDb

```


### 
```
垂直拆分
	是指按功能模块拆分，比如可以将群组相关表和照片相关表存放在不同的数据库中，这种方式多个数据库之间的表结构不同。比如在设计大型论坛时，我们可以把不同版面的数据存储到不同的数据库表或者不同的数据库中。
水平拆分
	而水平拆分是将同一个表的数据进行分块保存到不同的数据库中，这些数据库中的表结构完全相同。刚才说到的千万级的用户表所用到的办法就是水平拆分。
```


### 分布式数据库选型
```
1、OLAP
	https://www.cnblogs.com/mq0036/p/4155832.html
	https://blog.csdn.net/xwc35047/article/details/86369465

	联机分析处理（Online Analytical Processing）
	主要做数据仓库，主要对数据的查询，读多写少，做分析处理，复杂的分析操作，主要应用于大规模计算系统
	场景：分析决策，报表统计
	要求：无需事务支持
	数据操作：查询为主
	实时性：低
	DB大小：大(GB-TB)
	(1) 基本概念
		1) 维
			维度模型的概念出自于数据仓库领域，是数据仓库建设中的一种数据建模方法。维度模型主要由事实表和维度表这两个基本要素构成
		2) 操作
			下探(Drill down)：维度是有层次的，下探表示进入维度的下一层
			上钻(Drill up)： 下探的反向操作，回到更高汇聚层的汇总数据
			切片(Slice)：切片可以理解成把立体按某一个维度进行切分
			切块(Dice)：相对于切片是按一个点切分，切块就是按一个范围(区间)来做切分。
			旋转(Pivot)：维的行列位置交换，换一个视角分析数据。
		3) 系统分类
			1) MPP架构的系统
				> MPP
					大规模并行处理
					在数据库非共享集群中，每个节点都有独立的磁盘存储系统和内存系统，业务数据根据数据库模型和应用特点划分到各个节点上，每台数据节点通过专用网络或者商业通用网络互相连接，彼此协同计算，作为整体提供数据库服务。非共享数据库集群有完全的可伸缩性、高可用、高性能、优秀的性价比、资源共享等优势
				Presto/Impala/SparkSQL/Drill等
				有很好的数据量和灵活性支持，但是对响应时间是没有保证的
				当数据量和计算复杂度增加后，响应时间会变慢

			2) 搜索引擎架构的系统
				Elasticsearch
				在入库时将数据转换为倒排索引，牺牲了灵活性换取很好的性能，在搜索类查询上能做到亚秒级响应
				但是对于扫描聚合为主的查询，随着处理数据量的增加，响应时间也会退化到分钟级

			3) 预计算系统
				Druid/Kylin
				在入库时对数据进行预聚合，进一步牺牲灵活性换取性能，以实现对超大数据集的秒级响应
	(2) 分类
		1) 用于纯计算框架的SQL on hadoop
			Impala是用于处理存储在Hadoop集群中的大量数据的MPP（大规模并行处理）SQL查询引擎。 它是一个用C ++和Java编写的开源软件。 与其他Hadoop的SQL引擎相比，它提供了高性能和低延迟

		

	(3) 案例
		1) Druid
			alibaba/java
			
		2) Presto
			Facebook/java
		3) Kylin
			Apache/java

	(4) 不推荐Hive，太慢

2、OLTP
	https://www.talkwithtrend.com/Article/248323

	联机事务处理（Online Transaction Processing）
	事务性非常高，主要对数据的增删改
	典型的OLTP系统有电子商务系统、银行、证券
	把这类数据库又叫做newsql，有两种实现方式
	(1) 数据库访问中间件(分库分表)
		依靠传统的关系型数据库，通过数据库分库分表的方式，满足扩展性要求
		MySQL、postgresql、中间件(Cobar、MyCAT)
		优点：中间件可以自由发挥
		缺点：在保证分布式事务一致性时，性能有所下降
	(2) NewSQL数据库
		1) 概念
			针对OLTP的读写，提供与NOSQL相同的可扩展性和性能，同时能支持满足ACID特性的事务
			即保持NoSQL的高可扩展和高性能，并且保持关系模型
		2) 为什么需要NewSQL
			NoSQL 不能完全取代 RDBMS
			单机RDBMS 无法满足性能需求
			使用“单机RDBMS + 中间件”方式，在中间件层很难解决分布式事务、高可用问题
		3) 案例
			Google Spanner/F1
			TiDB(开源)
			OceanBase
		优点：见上述
		缺点：无法人工干预(内部支持分库分表)，业界案例少，可靠稳定有待验证


		

```
