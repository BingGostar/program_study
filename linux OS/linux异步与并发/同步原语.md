### 内存屏障
1、cpu缓存架构
```
http://www.wowotech.net/kernel_synchronization/memory-barrier.html

                            Main Memory
                                ↑
                                ↓
                        System Bus Interface 
                                ↑               
                                ↓               
            +--------------- L2 Cache <-----------------------+    
            |                   ↑                             |  
            ↓                   ↓                             |  
    L1 Instruction Cache     L1 Data Cache                    | 
            ↑                 ↑         ↑                     |
            |          Load Buffer   Store Buffer ---> Write-Combining Buffers 
            |                 ↑         ↑
            |                 |         |
            +------------->Execution Units
                              Registers


// cache
    cpu中的cache是一行一行的，每行可存储多个变量，每行都有自己的cache状态

// cache状态
    M（修改, Modified）: 本地处理器已经修改缓存行, 即是脏行, 它的内容与内存中的内容不一样. 并且此cache只有本地一个拷贝（专有）。
    E（专有, Exclusive）: 缓存行内容和内存中的一样, 而且其它处理器都没有这行数据。
    S（共享, Shared）: 缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝。
    I（无效, Invalid）: 缓存行失效, 不能使用。
    modified状态和exclusive状态都是独占该cacheline, 但是modified状态下，cacheline的数据是dirty的，而exclusive状态下，cacheline中的数据和memory中的数据是一致的

// cache状态变化
    cache line状态           动作
    invalid
       |                cpu0读取变量，发生cache miss(cold miss)
       ↓                从memory加载到cache0的cache line中
    shared                  ↓
       |                此时cpu0想要修改cache0 
       ↓                cpu0发送read invalidate，加载了cache0的cache line
    exclusive(cpu0)         
    invalid(其他cpu)        ↓    
       ↓                对cache进行写操作
    modified(cpu0)          ↓
                        当该cache line被替换出cache的时候，modified状态的cacheline需要write back到memory中，而exclusive状态不需要

// store buffer
    当该cache line没有被替换出cache的时候，其他cpu读取该共享变量，由于之前已经变成invalid，则发生cache miss(communiction miss)。由于cpu0的cache line是modified状态，它必须响应这个读得操作
    从一个CPU的cacheline传递数据到另外一个CPU的cacheline是非常消耗时间的
    每个cpu写操作不必等到cache line被加载（exclusive状态），而是直接写到store buffer中然后去干其他的活。在CPU n的cache line把数据传递到其cache 0的cacheline之后，硬件将store buffer中的内容写入cache line。

```
2、 cpu乱序执行和编译器重排
```
代码顺序并不是真正的执行顺序，只要有空间提高性能，CPU和编译器可以进行各种优化。

// cpu乱序执行
    在一个固定长度的执行队列中，寻找可以同时执行的指令。这个过程只需考虑指令间是否有依赖关系，不需要理解程序的意图

// 编译器重排
    比处理器的范围更大，能在很大范围内进行代码分析,从而做出更优的策略,充分利用处理器的乱序执行功能.

```
3、 内存屏障
```
https://www.jianshu.com/p/64240319ed60
http://ifeve.com/linux-memory-barriers/
http://ifeve.com/memory-barriers-or-fences/

(1) 可见性与重排序
    1) 可见性
        cpu不同级别的Cache缓存，可以提高性能，但是多核时代会导致一致性问题
        例如：
            Core0与Core1命中了内存中的同一个地址，那么各自的L1 Cache会缓存同一份数据的副本
            Core0修改自己的L1 Cache，而Core1的L1 Cache的值没变
    2) 重排序
        > 真·重排序
            编译器、底层硬件（CPU等）出于“优化”的目的，按照某种规则将指令重新排序
            指令被发送到一个指令序列（也称执行缓冲区或者保留站）中。指令将在序列中等待，直到它的数据运算对象是可以获取的。然后被送到执行单元
        > 伪·重排序
            由于缓存同步顺序等问题，看起来指令被重排序了
        > 来源
            编译器编译时的优化 真·重排序
            处理器执行时的乱序优化 真·重排序
            缓存同步顺序（导致可见性问题）伪·重排序


(2) 什么是内存屏障
    一个系统中，CPU和其它硬件可以使用各种技巧来提高性能，包括内存操作的重排、延迟和合并；预取；推测执行分支以及各种类型的缓存。内存屏障是用来禁用或抑制这些技巧的，使代码稳健地控制多个CPU和(或)设备的交互
    不同的CPU架构上内存屏障的实现非常不一样，内存屏障是cpu技术

(3) 内存屏障功能
    1) 屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性
    2) 实现内存数据可见性，确保内存数据会同步到CPU缓存子系统
    注意：可见性可以认为是最弱的“一致性”（弱一致），只保证用户见到的数据是一致的，但不保证任意时刻，存储的数据都是一致的（强一致）。下文会讨论“缓存可见性”问题，部分文章也会称为“缓存一致性”问题。

(4) 重排序场景
    1) 编译器编译时的优化
        volatile禁用编译器优化
        解决了编译器重排
    2) 处理器执行时的乱序优化
        特殊的指令
        解决了cpu重排
    3) 缓存同步顺序（导致可见性问题）
        MESI协议，解决CPU缓存层面的问题
        解决了内存可见性


(5) 内存屏障
    1) 屏障类型
        > LoadLoad Barriers
            指令示例: Load1;LoadLoad;Load2	
            说明: 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作
        > StoreStore Barriers
            指令示例: Store1;StoreStore;Store2
            说明: 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作
        > LoadStore Barriers
            指令示例: Load1;LoadStore;Store2
            说明: 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作
        > StoreLoad Barriers
        	指令示例: Store1;StoreLoad;Load2	
            说明: 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作。它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令
            注意：
                该屏障同时具备其他三个屏障的效果，因此也称之为全能屏障（mfence），是目前大多数处理器所支持的；但是相对其他屏障，该屏障的开销相对昂贵。然而，除了mfence，不同的CPU架构对内存屏障的实现方式与实现程度非常不一样
    2) x86内存屏障(指令)
        > Store Barrier
            sfence指令，相当于StoreStore Barriers
            强制所有在sfence指令之前的store指令，都在该sfence指令执行之前被执行，发送缓存失效信号，并把store buffer中的数据刷出到CPU的L1 Cache中；所有在sfence指令之后的store指令，都在该sfence指令执行之后被执行。即，禁止对sfence指令前后store指令的重排序跨越sfence指令，使所有Store Barrier之前发生的内存更新都是可见的
        > Load Barrier
            lfence指令，相当于LoadLoad Barriers  
            强制所有在lfence指令之后的load指令，都在该lfence指令执行之后被执行，并且一直等到load buffer被该CPU读完才能执行之后的load指令（发现缓存失效后发起的刷入）。即，禁止对lfence指令前后load指令的重排序跨越lfence指令，配合Store Barrier，使所有Store Barrier之前发生的内存更新，对Load Barrier之后的load操作都是可见的
        > Full Barrier
            mfence指令，相当于StoreLoad Barriers
            mfence指令综合了sfence指令与lfence指令的作用，强制所有在mfence指令之前的store/load指令，都在该mfence指令执行之前被执行；所有在mfence指令之后的store/load指令，都在该mfence指令执行之后被执行。即，禁止对mfence指令前后store/load指令的重排序跨越mfence指令，使所有Full Barrier之前发生的操作，对所有Full Barrier之后的操作都是可见的


(6) 什么地方需要内存障碍？
    在正常操作下，一个单线程代码片段中内存操作重排序一般不会产生问题，仍然可以正常工作，即使是在一个SMP内核系统中也是如此。但是，下面四种场景下，重新排序可能会引发问题：
    > 多理器间的交互
    > 原子操作
    > 设备访问
    > 中断
```

### memory order
```
c++提供了6种标准的memory order实现


```

### std::atomic
```
```

### spin lock的优化
```
https://zhuanlan.zhihu.com/p/84617791?utm_source=qq&utm_medium=social&utm_oi=555400798499188736


```

