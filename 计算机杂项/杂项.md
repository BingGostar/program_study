# 指令集体系结构(ISA)
## 定义
```
> 指令集体系结构
> 逻辑设计和硬件控制语言HCL
> 顺序实现
> 流水线原理
> 流水线实现

(1) 概念
一个处理器支持的指令和指令的字节级编码就是这个处理器的ISA

ISA 在编译器编写者和处理器设计人之间提供了一个抽象概念层，编译器编写者只需要知道允许哪些指令，以及它们是如何编码的；而处理器设计者必须建造出这些指令的处理器。

可见部分包括：寄存器、存储器、条件码、PC（程序计数器）、程序状态。

(2) 作用
ISA在编译器编写者（CPU软件）和处理器设计人员（CPU硬件）之间提供了一个抽象层
```

#### cpu分支预测、流水线和条件转移
(1)流水线
指令从取值到真正执行的过程划分成多个小步骤(取指、译码、执行、访存、写回)，cpu真正开始执行指令序列时，一步压一步的执行，减少其等待时间。
```
每一步是一个时钟周期，如果级数越多，每个周期执行的就越多，性能就越好（注意！不是越多越好）
1->2->3
   1->2->3
      1->2->3
每个时钟周期都完成一条指令的性能      
```

(2)分支预测
如果猜对了，火车可以直接开往要去的方向
如果猜错了，火车要停下来，然后倒车，然后将车轨扳到正确的方向，然后火车重新开往正确的方向。
如果预测对了，那就不用停下来了
[分支预测](https://www.cnblogs.com/yangecnu/p/4196026.html)

(3)likely和unlikely
```
#define likely(x)  __builtin_expect(!!(x), 1)
#define unlikely(x)    __builtin_expect(!!(x), 0)
//上述源码中采用了内建函数__builtin_expect来进行定义,__builtin_expect函数用来引导gcc进行条件分支预测
```

### 原码、反码、补码
```
(1) 原码
    原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值
    比如如果是8位二进制:
    [+1]原 = 0000 0001
    [-1]原 = 1000 0001

(2) 反码
    1) 为什么需要反码
        原码最大的问题就在于一个数加上他的相反数不等于零
        例如：0001+1001=1010 (1+(-1)=-2) 0010+1010=1100 (2+(-2)=-4)
        反码的设计思想就是冲着解决这一点，既然一个负数是一个正数的相反数，那我们干脆用一个正数按位取反来表示负数试试
    2) 什么是反码
        正数的反码还是等于原码
        负数的反码就是他的原码除符号位外，按位取反
        [+1] = [00000001]原 = [00000001]反
        [-1] = [10000001]原 = [11111110]反

        0001+1110=1111 （1+（-1）= - 0）
        互为相反数相加等于0，解决。虽然是得到的结果是1111也就是-0

(3) 补码
    1) 为什么需要补码
        1 - 1 = [0000 0001]反 + [1111 1110]反 = [1111 1111]反 = [1000 0000]原 = -0

    2) 什么是补码
        正数的补码就是其本身
        负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)
        [+1] = [00000001]原 = [00000001]反 = [00000001]补
        [-1] = [10000001]原 = [11111110]反 = [11111111]补
        
        1-1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原 = [0000 0001]补 + [1111 1111]补 = [0000 0000]补=[0000 0000]原

        (-1) + (-127) = [1000 0001]原 + [1111 1111]原 = [1111 1111]补 + [1000 0001]补 = [1000 0000]补=[1111 1111]原
```

### 图像系统架构
```
https://blog.csdn.net/huoyahuoya/article/details/54708295
https://www.cnblogs.com/liqiu/p/3499582.html
https://blog.csdn.net/u013895853/article/details/81586915
https://blog.csdn.net/youyou1543724847/article/details/84192430 ❗


(1) Windowing system（窗口系统）
    > client-server架构
        server（称作display server，或者windows server、compositor等等）管理所有输入设备，以及用于输出的显示设备
    > x client
        应用程序作为display server的一个client，在自己窗口（window）中运行，并绘制自己的GUI
    > x server
        client的绘图请求，都会提交给display server，display server响应并处理这些请求，以一定的规则混合、叠加，最终在有限的输出资源上
    > x protocol
        display server和自己的client之间，通过某种类型的通信协议交互，该通信协议通常称作display server protocol
    
    X client <--> X protocol <--> X server <--> linux kernel

(2) X Window System
    Windowing System一种实现，X Window 系统广泛的应用于桌面 Linux
    架构
              keyborad mouse screen
                 ↑       ↑     ↑
        +------------------------------+
        |  +------------------------+  |
        |  |        x server        |  |
        |  +------------------------+  |  
        |     ↑          ↑        ↑    | 
        |     ↓          ↓        |    |
        | x client   x client     |    |
        | (browser)  (browser)    |    |
        +-------------------------|----+
                                  |
                                 net  
                                  |
                                remote
    注意：
        X只提供实现GUI环境的基本框架，如定义protocol、在显示设备上绘制基本的图形单元（点、线、面等等）、和鼠标键盘等输入设备交互、等等。它并没有实现UI设计所需的button、menu、window title-bar styles等元素，而是由第三方的应用程序提供。


(3) 窗口管理器、GUI工具集、桌面环境及其它
    1) 窗口管理器(application windows)
        负责控制应用程序窗口的布局和外观，使每个应用程序窗口尽量以统一、一致的方式呈现给用户，如针对X的最简单的窗口管理程序–twm（Tab Window Manager）
    2) GUI工具集
        GUI工具集是Windowing system之上的进一步的封装。
        xlib提供给应用程序的API，仅仅可以绘制基本的图形单元（点、线、面等等），这些基本的图形单元
        在xlib基础上封装出一些更为便利的GUI接口，方便应用程序使用，如Microwindows、GTK+、QT等等
    3) 桌面环境
        桌面环境是应用程序级别的封装，通过提供一系列界面一致、操作方式一致的应用程序，使系统以更为友好的方式向用户提供服务。Linux系统比较主流的桌面环境包括GNOME、KDE等

    xlib -> GTK/QT -> GNOME/KDE

(4) 3D渲染、硬件加速、openGL等
    OpenGL只是一个API，它与Applications和Toolkits，应用软件同级
    对上，屏蔽硬件细节，为应用程序提供相对稳定的、平台无关的3D图像处理API
    对下，指引硬件相关的驱动软件，实现3D图像处理相关的功能
```
![系统架构](https://upload.wikimedia.org/wikipedia/commons/c/c2/Linux_Graphics_Stack_2013.svg)

### SaaS PaaS LaaS
```
https://www.zhihu.com/question/20387284

// LaaS(Infrastructure as a service – 基础设施即服务)
    用户可以在云服务提供商提供的基础设施上部署和运行任何软件，包括操作系统和应用软件
    常见的IaaS服务有虚拟机、虚拟网络、以及存储（阿里云、Amazon EC2）

// PaaS(Platform as a service – 平台即服务)
    PaaS给用户提供的能力是使用由云服务提供商支持的编程语言、库、服务以及开发工具来创建、开发应用程序并部署在相关的基础设施上
    常见的PaaS服务有数据库服务、web应用以及容器服务

// SaaS(Software as a Service – 软件即服务)
    给用户提供的能力是使用在云基础架构上运行的云服务提供商的应用程序
    类似的服务有：各类的网盘(Dropbox、百度网盘等)，JIRA，GitLab，qq
```

### js
```
(1)PhantomJS浏览器内核，可以在linux运行浏览器，爬虫的终极解决方案
```

### 安全
```
rootkit
```

### 激活 win10
```
slmgr.vbs /upk
slmgr /ipk 2F77B-TNFGY-69QQF-B8YKP-D69TJ
slmgr /skms kms.03k.org
slmgr /ato
```

### openstack，docker，mesos，k8s 关系
```
OpenStack
    针对 Iaas 平台，以资源为中心，可以为上层的 PaaS 平台提供存储、网络、计算等资源

Docker
    主要针对 Paas 平台，是以应用为中心

Kubernetes(k8s)
    面向应用的 PaaS 层，强项在于容器编排，可以很好解决应用上云的问题

Mesos
    Apache的顶级开源项目，管理的核心目标对象既不是虚拟机/物理机，也不是容器，而是各种各样的计算资源（CPU、memory、disk、port、GPU等等）

```

### k8s + docker
```
k8s用于容器和虚拟机集群的管理，一切都基于分布式

一个K8S系统，通常称为一个K8S集群（Cluster）
这个集群主要包括两个部分：一个Master节点（主节点）和一群Node节点（计算节点）


1、Master组件
    Master组件提供集群的管理控制中心，它可以在集群中任何节点上运行
    (1) kube-apiserver
        用于暴露Kubernetes API。任何的资源请求/调用操作都是通过kube-apiserver提供的接口进行
    (2) ETCD
        etcd是Kubernetes提供默认的一致性系统，可用于存储集群的相关数据
    (3) kube-controller-manager
        管理控制器，它们是集群中处理常规任务的后台线程。逻辑上，每个控制器是一个单独的进程
        1) 节点（Node）控制器
        2) 副本（Replication）控制器
            负责维护系统中每个副本中的pod
        3) 端点（Endpoints）控制器
            填充Endpoints对象（即连接Services＆Pods）
        4) Service Account和Token控制器
            为新的Namespace 创建默认帐户访问API Token
    (4) cloud-controller-manager
        1) 节点（Node）控制器
        2) 路由（Route）控制器
        3) Service控制器
        4) 卷（Volume）控制器
    (5) kube-scheduler
        监视新创建没有分配到Node的Pod，为Pod选择一个Node

2、Node组件
    提供Kubernetes运行时环境，以及维护Pod。一个Node可以是VM或物理机
    (1) kubelet
        kubelet是主要的节点代理，它会监视已分配给节点的pod
        安装Pod所需的volume、下载Pod、Pod中运行的 docker（或experimentally，rkt）容器、定期执行容器健康检查等
    (2) kube-proxy
        维护网络规则并执行连接转发来实现Kubernetes服务抽象，每一个节点也运行一个简单的网络代理和负载均衡
    (3) docker
        docker用于运行容器
    (4) RKT
        rkt运行容器，作为docker工具的替代方案
    (5) supervisord
        supervisord是一个轻量级的监控系统，用于保障kubelet和docker运行
    (6) fluentd
        fluentd是一个守护进程，可提供cluster-level logging


```

### cpu缓存架构
```
http://www.wowotech.net/kernel_synchronization/memory-barrier.html

                            Main Memory
                                ↑
                                ↓
                        System Bus Interface 
                                ↑               
                                ↓               
            +--------------- L2 Cache <-----------------------+    
            |                   ↑                             |  
            ↓                   ↓                             |  
    L1 Instruction Cache     L1 Data Cache                    | 
            ↑                 ↑         ↑                     |
            |          Load Buffer   Store Buffer ---> Write-Combining Buffers 
            |                 ↑         ↑
            |                 |         |
            +------------->Execution Units
                              Registers


// cache
    cpu中的cache是一行一行的，每行可存储多个变量，每行都有自己的cache状态

// MESI协议
    https://www.jianshu.com/p/94200fc2d3f1
    来确保硬件级别Cache一致性（Cache Coherence）
    > cache状态
        M（修改, Modified）: 本地处理器已经修改缓存行, 即是脏行, 它的内容与内存中的内容不一样. 并且此cache只有本地一个拷贝（专有）。
        E（专有, Exclusive）: 缓存行内容和内存中的一样, 而且其它处理器都没有这行数据。
        S（共享, Shared）: 缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝。
        I（无效, Invalid）: 缓存行失效, 不能使用。
        modified状态和exclusive状态都是独占该cacheline, 但是modified状态下，cacheline的数据是dirty的，而exclusive状态下，cacheline中的数据和memory中的数据是一致的
    > cache操作
        local read（LR）：读本地cache中的数据；
        local write（LW）：将数据写到本地cache；
        remote read（RR）：其他核心发生read；
        remote write（RW）：其他核心发生write；
    > cache状态转换
        > 初始场景
            在最初的时候，所有CPU中都没有数据，某一个CPU发生读操作，此时必然发生cache miss，数据从主存中读取到当前CPU的cache，状态为E（独占，只有当前CPU有数据，且和主存一致），此时如果有其他CPU也读取数据，则状态修改为S（共享，多个CPU之间拥有相同数据，并且和主存保持一致），如果其中某一个CPU发生数据修改，那么该CPU中数据状态修改为M（拥有最新数据，和主存不一致，但是以当前CPU中的为准），其他拥有该数据的核心通过缓存控制器监听到remote write行文，然后将自己拥有的数据的cache line状态修改为I（失效，和主存中的数据被认为不一致，数据不可用应该重新获取）。
        > modify
            当前CPU中数据的状态是modify，表示当前CPU中拥有最新数据，虽然主存中的数据和当前CPU中的数据不一致，但是以当前CPU中的数据为准；
            LR：此时如果发生local read，即当前CPU读数据，直接从cache中获取数据，拥有最新数据，因此状态不变；
            LW：直接修改本地cache数据，修改后也是当前CPU拥有最新数据，因此状态不变；
            RR：因为本地内存中有最新数据，当本地cache控制器监听到总线上有RR发生的时，必然是其他CPU发生了读主存的操作，此时为了保证一致性，当前CPU应该将数据写回主存，而随后的RR将会使得其他CPU和当前CPU拥有共同的数据，因此状态修改为S；
            RW：同RR，当cache控制器监听到总线发生RW，当前CPU会将数据写回主存，因为随后的RW将会导致主存的数据修改，因此状态修改成I；
        > exclusive
            当前CPU中的数据状态是exclusive，表示当前CPU独占数据（其他CPU没有数据），并且和主存的数据一致；
            LR：从本地cache中直接获取数据，状态不变；
            LW：修改本地cache中的数据，状态修改成M（因为其他CPU中并没有该数据，因此不存在共享问题，不需要通知其他CPU修改cache line的状态为I）；
            RR：本地cache中有最新数据，当cache控制器监听到总线上发生RR的时候，必然是其他CPU发生了读取主存的操作，而RR操作不会导致数据修改，因此两个CPU中的数据和主存中的数据一致，此时cache line状态修改为S；
            RW：同RR，当cache控制器监听到总线发生RW，发生其他CPU将最新数据写回到主存，此时为了保证缓存一致性，当前CPU的数据状态修改为I；
        > shared
            当前CPU中的数据状态是shared，表示当前CPU和其他CPU共享数据，且数据在多个CPU之间一致、多个CPU之间的数据和主存一致；
            LR：直接从cache中读取数据，状态不变；
            LW：发生本地写，并不会将数据立即写回主存，而是在稍后的一个时间再写回主存，因此为了保证缓存一致性，当前CPU的cache line状态修改为M，并通知其他拥有该数据的CPU该数据失效，其他CPU将cache line状态修改为I；
            RR：状态不变，因为多个CPU中的数据和主存一致；
            RW：当监听到总线发生了RW，意味着其他CPU发生了写主存操作，此时本地cache中的数据既不是最新数据，和主存也不再一致，因此当前CPU的cache line状态修改为I；
        > invalid
            当前CPU中的数据状态是invalid，表示当前CPU中是脏数据，不可用，其他CPU可能有数据、也可能没有数据；
            LR：因为当前CPU的cache line数据不可用，因此会发生读内存，此时的情形如下。
                A. 如果其他CPU中无数据则状态修改为E；
                B. 如果其他CPU中有数据且状态为S或E则状态修改为S；
                C. 如果其他CPU中有数据且状态为M，那么其他CPU首先发生RW将M状态的数据写回主存并修改状态为S，随后当前CPU读取主存数据，也将状态修改为S；
            LW：因为当前CPU的cache line数据无效，因此发生LW会直接操作本地cache，此时的情形如下。
                A. 如果其他CPU中无数据，则将本地cache line的状态修改为M；
                B. 如果其他CPU中有数据且状态为S或E，则修改本地cache，通知其他CPU将数据修改为I，当前CPU中的cache line状态修改为M；
                C. 如果其他CPU中有数据且状态为M，则其他CPU首先将数据写回主存，并将状态修改为I，当前CPU中的cache line转台修改为M；
            RR：监听到总线发生RR操作，表示有其他CPU读取内存，和本地cache无关，状态不变；
            RW：监听到总线发生RW操作，表示有其他CPU写主存，和本地cache无关，状态不变；

    > 这个协议有两个行为的执行成本比较大：
        一个是将某个Cache Line标记为Invalid状态
        一个是当某Cache Line当前状态为Invalid时写入新的数据
    > 所以CPU通过Store Buffer和Invalidate Queue组件来降低这类操作的延时

// 示例
    cache line状态           动作
    invalid
       |                cpu0读取变量，发生cache miss(cold miss)
       ↓                从memory加载到cache0的cache line中
    shared                  ↓
       |                此时cpu0想要修改cache0 
       ↓                cpu0发送read invalidate，加载了cache0的cache line
    exclusive(cpu0)         
    invalid(其他cpu)        ↓    
       ↓                对cache进行写操作
    modified(cpu0)          ↓
                        当该cache line被替换出cache的时候，modified状态的cacheline需要write back到memory中，而exclusive状态不需要


// store buffer
    当该cache line没有被替换出cache的时候，其他cpu读取该共享变量，由于之前已经变成invalid，则发生cache miss(communiction miss)。由于cpu0的cache line是modified状态，它必须响应这个读得操作
    从一个CPU的cacheline传递数据到另外一个CPU的cacheline是非常消耗时间的
    每个cpu写操作不必等到cache line被加载（exclusive状态），而是直接写到store buffer中然后去干其他的活。在CPU n的cache line把数据传递到其cache 0的cacheline之后，硬件将store buffer中的内容写入cache line。

// Invalidate Queue

```