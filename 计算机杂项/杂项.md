# 指令集体系结构(ISA)
## 定义
```
> 指令集体系结构
> 逻辑设计和硬件控制语言HCL
> 顺序实现
> 流水线原理
> 流水线实现

(1) 概念
一个处理器支持的指令和指令的字节级编码就是这个处理器的ISA

ISA 在编译器编写者和处理器设计人之间提供了一个抽象概念层，编译器编写者只需要知道允许哪些指令，以及它们是如何编码的；而处理器设计者必须建造出这些指令的处理器。

可见部分包括：寄存器、存储器、条件码、PC（程序计数器）、程序状态。

(2) 作用
ISA在编译器编写者（CPU软件）和处理器设计人员（CPU硬件）之间提供了一个抽象层
```

#### cpu分支预测、流水线和条件转移
(1)流水线
指令从取值到真正执行的过程划分成多个小步骤(取指、译码、执行、访存、写回)，cpu真正开始执行指令序列时，一步压一步的执行，减少其等待时间。
```
每一步是一个时钟周期，如果级数越多，每个周期执行的就越多，性能就越好（注意！不是越多越好）
1->2->3
   1->2->3
      1->2->3
每个时钟周期都完成一条指令的性能      
```

(2)分支预测
如果猜对了，火车可以直接开往要去的方向
如果猜错了，火车要停下来，然后倒车，然后将车轨扳到正确的方向，然后火车重新开往正确的方向。
如果预测对了，那就不用停下来了
[分支预测](https://www.cnblogs.com/yangecnu/p/4196026.html)

(3)likely和unlikely
```
#define likely(x)  __builtin_expect(!!(x), 1)
#define unlikely(x)    __builtin_expect(!!(x), 0)
//上述源码中采用了内建函数__builtin_expect来进行定义,__builtin_expect函数用来引导gcc进行条件分支预测
```

### 原码、反码、补码
```
(1) 原码
    原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值
    比如如果是8位二进制:
    [+1]原 = 0000 0001
    [-1]原 = 1000 0001

(2) 反码
    1) 为什么需要反码
        原码最大的问题就在于一个数加上他的相反数不等于零
        例如：0001+1001=1010 (1+(-1)=-2) 0010+1010=1100 (2+(-2)=-4)
        反码的设计思想就是冲着解决这一点，既然一个负数是一个正数的相反数，那我们干脆用一个正数按位取反来表示负数试试
    2) 什么是反码
        正数的反码还是等于原码
        负数的反码就是他的原码除符号位外，按位取反
        [+1] = [00000001]原 = [00000001]反
        [-1] = [10000001]原 = [11111110]反

        0001+1110=1111 （1+（-1）= - 0）
        互为相反数相加等于0，解决。虽然是得到的结果是1111也就是-0

(3) 补码
    1) 为什么需要补码
        1 - 1 = [0000 0001]反 + [1111 1110]反 = [1111 1111]反 = [1000 0000]原 = -0

    2) 什么是补码
        正数的补码就是其本身
        负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)
        [+1] = [00000001]原 = [00000001]反 = [00000001]补
        [-1] = [10000001]原 = [11111110]反 = [11111111]补
        
        1-1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原 = [0000 0001]补 + [1111 1111]补 = [0000 0000]补=[0000 0000]原

        (-1) + (-127) = [1000 0001]原 + [1111 1111]原 = [1111 1111]补 + [1000 0001]补 = [1000 0000]补=[1111 1111]原
```

### 图像系统架构
```
https://blog.csdn.net/huoyahuoya/article/details/54708295
https://www.cnblogs.com/liqiu/p/3499582.html
https://blog.csdn.net/u013895853/article/details/81586915
https://blog.csdn.net/youyou1543724847/article/details/84192430 ❗


(1) Windowing system（窗口系统）
    > client-server架构
        server（称作display server，或者windows server、compositor等等）管理所有输入设备，以及用于输出的显示设备
    > x client
        应用程序作为display server的一个client，在自己窗口（window）中运行，并绘制自己的GUI
    > x server
        client的绘图请求，都会提交给display server，display server响应并处理这些请求，以一定的规则混合、叠加，最终在有限的输出资源上
    > x protocol
        display server和自己的client之间，通过某种类型的通信协议交互，该通信协议通常称作display server protocol
    
    X client <--> X protocol <--> X server <--> linux kernel

(2) X Window System
    Windowing System一种实现，X Window 系统广泛的应用于桌面 Linux
    架构
              keyborad mouse screen
                 ↑       ↑     ↑
        +------------------------------+
        |  +------------------------+  |
        |  |        x server        |  |
        |  +------------------------+  |  
        |     ↑          ↑        ↑    | 
        |     ↓          ↓        |    |
        | x client   x client     |    |
        | (browser)  (browser)    |    |
        +-------------------------|----+
                                  |
                                 net  
                                  |
                                remote
    注意：
        X只提供实现GUI环境的基本框架，如定义protocol、在显示设备上绘制基本的图形单元（点、线、面等等）、和鼠标键盘等输入设备交互、等等。它并没有实现UI设计所需的button、menu、window title-bar styles等元素，而是由第三方的应用程序提供。


(3) 窗口管理器、GUI工具集、桌面环境及其它
    1) 窗口管理器(application windows)
        负责控制应用程序窗口的布局和外观，使每个应用程序窗口尽量以统一、一致的方式呈现给用户，如针对X的最简单的窗口管理程序–twm（Tab Window Manager）
    2) GUI工具集
        GUI工具集是Windowing system之上的进一步的封装。
        xlib提供给应用程序的API，仅仅可以绘制基本的图形单元（点、线、面等等），这些基本的图形单元
        在xlib基础上封装出一些更为便利的GUI接口，方便应用程序使用，如Microwindows、GTK+、QT等等
    3) 桌面环境
        桌面环境是应用程序级别的封装，通过提供一系列界面一致、操作方式一致的应用程序，使系统以更为友好的方式向用户提供服务。Linux系统比较主流的桌面环境包括GNOME、KDE等

    xlib -> GTK/QT -> GNOME/KDE

(4) 3D渲染、硬件加速、openGL等
    OpenGL只是一个API，它与Applications和Toolkits，应用软件同级
    对上，屏蔽硬件细节，为应用程序提供相对稳定的、平台无关的3D图像处理API
    对下，指引硬件相关的驱动软件，实现3D图像处理相关的功能
```
![系统架构](https://upload.wikimedia.org/wikipedia/commons/c/c2/Linux_Graphics_Stack_2013.svg)

### SaaS PaaS LaaS
```
https://www.zhihu.com/question/20387284

// LaaS(Infrastructure as a service – 基础设施即服务)
    用户可以在云服务提供商提供的基础设施上部署和运行任何软件，包括操作系统和应用软件
    常见的IaaS服务有虚拟机、虚拟网络、以及存储（阿里云、Amazon EC2）

// PaaS(Platform as a service – 平台即服务)
    PaaS给用户提供的能力是使用由云服务提供商支持的编程语言、库、服务以及开发工具来创建、开发应用程序并部署在相关的基础设施上
    常见的PaaS服务有数据库服务、web应用以及容器服务

// SaaS(Software as a Service – 软件即服务)
    给用户提供的能力是使用在云基础架构上运行的云服务提供商的应用程序
    类似的服务有：各类的网盘(Dropbox、百度网盘等)，JIRA，GitLab，qq
```

### PhantomJS
```
PhantomJS浏览器内核，可以在linux运行浏览器，爬虫的终极解决方案
```

### 安全
```
rootkit
```

### 激活 win10
```
slmgr.vbs /upk
slmgr /ipk 2F77B-TNFGY-69QQF-B8YKP-D69TJ
slmgr /skms kms.03k.org
slmgr /ato
```

### openstack，docker，mesos，k8s 关系
```
OpenStack
    针对 Iaas 平台，以资源为中心，可以为上层的 PaaS 平台提供存储、网络、计算等资源

Docker
    主要针对 Paas 平台，是以应用为中心

Kubernetes(k8s)
    面向应用的 PaaS 层，强项在于容器编排，可以很好解决应用上云的问题

Mesos
    Apache的顶级开源项目，管理的核心目标对象既不是虚拟机/物理机，也不是容器，而是各种各样的计算资源（CPU、memory、disk、port、GPU等等）

```

### k8s + docker
```
k8s用于容器和虚拟机集群的管理，一切都基于分布式

一个K8S系统，通常称为一个K8S集群（Cluster）
这个集群主要包括两个部分：一个Master节点（主节点）和一群Node节点（计算节点）


1、Master组件
    Master组件提供集群的管理控制中心，它可以在集群中任何节点上运行
    (1) kube-apiserver
        用于暴露Kubernetes API。任何的资源请求/调用操作都是通过kube-apiserver提供的接口进行
    (2) ETCD
        etcd是Kubernetes提供默认的一致性系统，可用于存储集群的相关数据
    (3) kube-controller-manager
        管理控制器，它们是集群中处理常规任务的后台线程。逻辑上，每个控制器是一个单独的进程
        1) 节点（Node）控制器
        2) 副本（Replication）控制器
            负责维护系统中每个副本中的pod
        3) 端点（Endpoints）控制器
            填充Endpoints对象（即连接Services＆Pods）
        4) Service Account和Token控制器
            为新的Namespace 创建默认帐户访问API Token
    (4) cloud-controller-manager
        1) 节点（Node）控制器
        2) 路由（Route）控制器
        3) Service控制器
        4) 卷（Volume）控制器
    (5) kube-scheduler
        监视新创建没有分配到Node的Pod，为Pod选择一个Node

2、Node组件
    提供Kubernetes运行时环境，以及维护Pod。一个Node可以是VM或物理机
    (1) kubelet
        kubelet是主要的节点代理，它会监视已分配给节点的pod
        安装Pod所需的volume、下载Pod、Pod中运行的 docker（或experimentally，rkt）容器、定期执行容器健康检查等
    (2) kube-proxy
        维护网络规则并执行连接转发来实现Kubernetes服务抽象，每一个节点也运行一个简单的网络代理和负载均衡
    (3) docker
        docker用于运行容器
    (4) RKT
        rkt运行容器，作为docker工具的替代方案
    (5) supervisord
        supervisord是一个轻量级的监控系统，用于保障kubelet和docker运行
    (6) fluentd
        fluentd是一个守护进程，可提供cluster-level logging


```

### cpu缓存架构
```
http://www.wowotech.net/kernel_synchronization/memory-barrier.html

                            Main Memory
                                ↑
                                ↓
                        System Bus Interface 
                                ↑               
                                ↓               
            +--------------- L2 Cache <-----------------------+    
            |                   ↑                             |  
            ↓                   ↓                             |  
    L1 Instruction Cache     L1 Data Cache                    | 
            ↑                 ↑         ↑                     |
            |          Load Buffer   Store Buffer ---> Write-Combining Buffers 
            |                 ↑         ↑
            |                 |         |
            +------------->Execution Units
                              Registers


// cache
    cpu中的cache是一行一行的，每行可存储多个变量，每行都有自己的cache状态

// MESI协议
    https://www.jianshu.com/p/94200fc2d3f1
    来确保硬件级别Cache一致性（Cache Coherence）
    > cache状态
        M（修改, Modified）: 本地处理器已经修改缓存行, 即是脏行, 它的内容与内存中的内容不一样. 并且此cache只有本地一个拷贝（专有）。
        E（专有, Exclusive）: 缓存行内容和内存中的一样, 而且其它处理器都没有这行数据。
        S（共享, Shared）: 缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝。
        I（无效, Invalid）: 缓存行失效, 不能使用。
        modified状态和exclusive状态都是独占该cacheline, 但是modified状态下，cacheline的数据是dirty的，而exclusive状态下，cacheline中的数据和memory中的数据是一致的
    > cache操作
        local read（LR）：读本地cache中的数据；
        local write（LW）：将数据写到本地cache；
        remote read（RR）：其他核心发生read；
        remote write（RW）：其他核心发生write；

        一个Invalid的缓存行必须从主存中读取（变成S或者 E状态）来满足该CPU的读请求
        一个写请求只有在该缓存行是M或者E状态时才能被执行，如果缓存行处于S状态，必须先将其它缓存中该缓存行变成Invalid状态(该操作经常作用广播的方式来完成)

    > cache状态转换
        > 直接转换关系
            M  E  S  I
        M   ×  ×  ×  √  RW
        E   ×  ×  ×  √  RW
        S   ×  ×  √  √  LR/RR   LW/RW
        I   √  √  √  √  LW  LR  RR  RW

        > 初始场景
            初始状态下所有CPU中都没有数据
            某一个CPU发生读操作，此时必然发生cache miss，数据从主存中读取到当前CPU的cache，状态为E（独占，只有当前CPU有数据，且和主存一致）
            如果有其他CPU也读取该数据，则状态修改为S（共享，多个CPU之间拥有相同数据，并且和主存保持一致）
            如果其中某一个CPU发生数据修改，那么该CPU中数据状态修改为M（拥有最新数据，和主存不一致，但是以当前CPU中的为准）
            其他拥有该数据的核心通过缓存控制器监听到remote write行文，然后将自己拥有的数据的cache line状态修改为I（失效，和主存中的数据被认为不一致，数据不可用应该重新获取）
        > exclusive
            当前CPU中的数据状态是exclusive，表示当前CPU独占数据（其他CPU没有数据），并且和主存的数据一致；
            LR：从本地cache中直接获取数据，状态不变；
            LW：修改本地cache中的数据，状态修改成M（因为其他CPU中并没有该数据，因此不存在共享问题，不需要通知其他CPU修改cache line的状态为I）
            RR：本地cache中有最新数据，当cache控制器监听到总线上发生RR的时候，必然是其他CPU发生了读取主存的操作，而RR操作不会导致数据修改，因此两个CPU中的数据和主存中的数据一致，此时cache line状态修改为S
            RW：当cache控制器监听到总线发生RW，发生其他CPU将最新数据写回到主存，此时为了保证缓存一致性，当前CPU的数据状态修改为I
        > shared
            当前CPU中的数据状态是shared，表示当前CPU和其他CPU共享数据，且数据在多个CPU之间一致、多个CPU之间的数据和主存一致；
            LR：直接从cache中读取数据，状态不变
            LW：发生本地写，并不会将数据立即写回主存，而是在稍后的一个时间再写回主存，因此为了保证缓存一致性，当前CPU的cache line状态修改为M，并通知其他拥有该数据的CPU该数据失效，其他CPU将cache line状态修改为I
            RR：状态不变，因为多个CPU中的数据和主存一致
            RW：当监听到总线发生了RW，意味着其他CPU发生了写主存操作，此时本地cache中的数据既不是最新数据，和主存也不再一致，因此当前CPU的cache line状态修改为I
        > modify
            当前CPU中数据的状态是modify，表示当前CPU中拥有最新数据，虽然主存中的数据和当前CPU中的数据不一致，但是以当前CPU中的数据为准；
            LR：此时如果发生local read，即当前CPU读数据，直接从cache中获取数据，拥有最新数据，因此状态不变；
            LW：直接修改本地cache数据，修改后也是当前CPU拥有最新数据，因此状态不变；
            RR：因为本地内存中有最新数据，当本地cache控制器监听到总线上有RR发生的时，必然是其他CPU发生了读主存的操作，此时为了保证一致性，当前CPU应该将数据写回主存，而随后的RR将会使得其他CPU和当前CPU拥有共同的数据，因此状态修改为S；
            RW：同RR，当cache控制器监听到总线发生RW，当前CPU会将数据写回主存，因为随后的RW将会导致主存的数据修改，因此状态修改成I；
        
        > invalid
            当前CPU中的数据状态是invalid，表示当前CPU中是脏数据，不可用，其他CPU可能有数据、也可能没有数据；
            LR：因为当前CPU的cache line数据不可用，因此会发生读内存，此时的情形如下。
                A. 如果其他CPU中无数据则状态修改为E；
                B. 如果其他CPU中有数据且状态为S或E则状态修改为S；
                C. 如果其他CPU中有数据且状态为M，那么其他CPU首先发生RW将M状态的数据写回主存并修改状态为S，随后当前CPU读取主存数据，也将状态修改为S；
            LW：因为当前CPU的cache line数据无效，因此发生LW会直接操作本地cache，此时的情形如下。
                A. 如果其他CPU中无数据，则将本地cache line的状态修改为M；
                B. 如果其他CPU中有数据且状态为S或E，则修改本地cache，通知其他CPU将数据修改为I，当前CPU中的cache line状态修改为M；
                C. 如果其他CPU中有数据且状态为M，则其他CPU首先将数据写回主存，并将状态修改为I，当前CPU中的cache line转台修改为M；
            RR：监听到总线发生RR操作，表示有其他CPU读取内存，和本地cache无关，状态不变；
            RW：监听到总线发生RW操作，表示有其他CPU写主存，和本地cache无关，状态不变；

    > 这个协议有两个行为的执行成本比较大：
        一个是将某个Cache Line标记为Invalid状态
        一个是当某Cache Line当前状态为Invalid时写入新的数据
    > 所以CPU通过Store Buffer和Invalidate Queue组件来降低这类操作的延时

// 示例
    cache line状态           动作
    invalid
       |                cpu0读取变量，发生cache miss(cold miss)
       ↓                从memory加载到cache0的cache line中
    shared                  ↓
       |                此时cpu0想要修改cache0 
       ↓                cpu0发送read invalidate，加载了cache0的cache line
    exclusive(cpu0)         
    invalid(其他cpu)        ↓    
       ↓                对cache进行写操作
    modified(cpu0)          ↓
                        当该cache line被替换出cache的时候，modified状态的cacheline需要write back到memory中，而exclusive状态不需要


// store buffer
    当该cache line没有被替换出cache的时候，其他cpu读取该共享变量，由于之前已经变成invalid，则发生cache miss(communiction miss)。由于cpu0的cache line是modified状态，它必须响应这个读得操作
    从一个CPU的cacheline传递数据到另外一个CPU的cacheline是非常消耗时间的
    每个cpu写操作不必等到cache line被加载（exclusive状态），而是直接写到store buffer中然后去干其他的活。在CPU n的cache line把数据传递到其cache 0的cacheline之后，硬件将store buffer中的内容写入cache line。

// Invalidate Queue

```

### 普通文件系统、网络文件系统、分布式文件系统
```
(1) 文件系统
    文件系统对磁盘数据进行基本管理的一个软件层，Windows上用的FAT、NTFS，Linux下的ext4、XFS、btrfs都是常见的文件系统。

(2) 网络文件系统(CIFS、NFS)
    网络文件系统并不定义文件数据是如何在磁盘上面分布的，而是告诉网络中的客户端，文件数据应当如何传输，怎么通过网络访问远端的文件。所以，它实际上是搭建在普通文件系统之上的。提供网络文件服务的设备，需要有一个本地的文件系统（如ext4），然后在启动一个或多个网络文件系统，负责从普通文件系统中读取数据，向外传送。

(3) 分布式文件系统
    它们能把很多台电脑里的数据整合起来，对外表现出一个单一的存储节点，提供服务，实现性能扩展和高可靠性等高级特性。它们实际上也不会直接操作磁盘数据，而是叠加在普通文件系统之上的
```

### 物理存储分类
```
> 开放系统的存储
  > 内置存储
  > 外挂存储
    > 直连式存储(DAS)
    > 网络存储(FAS)
      > 网络接入存储(NAS)
      > 存储区域网络(SAN)

// DAS
  是以服务器为中心的存储架构，存储设备直接连在服务器主机上，然后服务器连在网络上，任何客户端想要访问存储设备上 的资源就必须要通过服器

// SAN
  https://www.zhihu.com/question/24669457/answer/28563178
  它与以太网平行，又名存储区域网络，专门用来给主机连接存储设备使用的网络，使用光纤、铜介质。使用FC协议(也可以使用ip协议)，SAN网络与LAN网相互隔离，不会影响彼此。
  分为FC-SAN和IP-SAN
  > FC-SAN                      IP-SAN
    应用服务器                   应用服务器
    文件系统        LAN          文件系统       LAN
       |                           |
    FC交换机                    GbE交换机
       |           SAN             |          LAN
     RAID RAID                   RAID  RAID

// NAS vs SAN
  > SAN存储设备通过光纤连接，而NAS存储设备通过TCP/IP连接
  > SAN和NAS系统都是可以使用RAID的冗余存储系统
  > SAN针对海量、面向数据块的数据传输,而NAS则提供文件级的数据访问和共享服务（NAS更是一种文件服务）
  > NAS:用户通过TCP/IP协议访问数据,采用业界标准文件共享协议如:NFS(linux)、HTTP、CIFS(windows)实
    SAN:通过专用光纤通道交换机访问数据,采用SCSI、FC-AL接口
  > SAN结构中,文件管理系统(FS)还是分别在每一个应用服务器上;
    NAS则是每个应用服务器通过网络共享协议(如:NFS、CIFS)使用同一个文件管理系统
    可以这样来比作：SAN是一个网络上的磁盘；NAS是一个网络上的文件系统。FC网络上的磁盘叫做SAN,把以太网络上的文件系统称为NAS，我们可以这样简单来理解。

// FC协议
  与tcp/ip平行，理解为SAN网络中的中的tcp/ip协议。遵守OSI模型
  
// NAS NFS
  http://www.voidcn.com/article/p-creinyyp-bs.html
  > NAS是存储类型
  > 常见的NAS有NFS(linux)和CIFS(windows)。
  > NFS是文件系统（一种网络文件系统），也可以理解为网络文件传输协议。就是定义文件数据如何在网络中传输，通过怎样的协议去访问网络端的文件。
    NAS指的是在网络中提供文件服务的设备。
  > 一般的NAS都支持NFS这种协议，当然还会支持CIFS、FTP等多种网络文件传输协议。
  > NFS缺点：局限性、性能、安全性(明文传输)、完整性

// ftp、nfs、smb文件传输协议比较
  协议相同点：都可以 实现文件传输系统
  协议不同点： 
    FTP（File Transfer Protocol，文件传输协议），应用层协议，可跨平台。如其名，只能实现文件传输功能，不能实现一些其他的功能，例如文件系统挂载等功能。

    NFS（Network File System，网路文件系统），工作在内核模式下的，故难以实现跨平台。由于基于文件系统实现，在linux下可实现挂载使用等功能。

    SMB（Service Message Block，服务消息块协议），能够实现Windows和Linux主机之间的文件共享服务，可实现跨平台，在Linux上实现了CIFS（Common Internet File System）协议。
```

### 存储接口类型
```
https://www.infoq.cn/article/virtual-forum-three-basic-issues-about-distributed-storage/

// 分布式存储类型及接口
(1) 对象存储: 也就是通常意义的键值存储，其接口就是简单的GET、PUT、DEL和其他扩展，如七牛、又拍、Swift、S3

(2) 块存储: 这种接口通常以QEMU Driver或者Kernel Module的方式存在，这种接口需要实现Linux的Block Device的接口或者QEMU提供的Block Driver接口，如Sheepdog，AWS的EBS，青云的云硬盘和阿里云的盘古系统，还有Ceph的RBD（RBD是Ceph面向块存储的接口）

(3) 文件存储: 通常意义是支持POSIX接口，它跟传统的文件系统如Ext4是一个类型的，但区别在于分布式存储提供了并行化的能力，如Ceph的CephFS(CephFS是Ceph面向文件存储的接口)，但是有时候又会把GFS，HDFS这种非POSIX接口的类文件存储接口归入此类。

//文件和对象存储都是对块存储的包装

```

### 流媒体
```
1、流媒体
    流媒体是指采用'流式传输'的方式在Internet播放的媒体格式
    流媒体最大的特点就是'边下边播'

2、流式传输
    流式传输分为'实时流式传输'与'顺序流式传输'
    如果视频为直播，即为实时流式传输
    如果视频不是直播，文件通过顺序流发送，即为顺序流式传输

3、视频传输
    将采集到的音频转成原始数据格式'PCM'
    将采集到的视频转成原始数据格式'RGB'或'YUV'
    
    编码视频格式从'RGB'到'H.265'
    编码音频格式从'PCM'到'AAC'

    通过视频传输协议将音视频('H.265'和'AAC')结合成数据包(FLV、TS、RTMP Packet)

4、解复用
    解复用是指从'音频视频信号源'中分流出'单独的音频'与'单独的视频'数据，比如我们将'FLV'解复用会得到'H.264视频数据'和'AAC音频数据'

5、视频传输协议
    应用层：RTSP、RTMP
    传输层：RTCP、RTP、TCP、UDP
    网络层：IP、RSVP

    (1) 实时传输协议RTP和RTCP
        RTP标准定义了两个协议，一个是RTP协议（数据传输协议），另一个是RTCP协议（控制协议）
        1) RTP
            针对多媒体数据流的一种实时传输协议
            RTP协议是建立在UDP协议上的
            RTP本身并没有提供按时发送机制或其他服务质量保证，不保证传送或防止无序传送，也不确定底层网络的可靠性

        2) RTCP
            实时传输控制协议，RTCP为RTP媒体流提供信道外控制
            一般与RTP配合使用

    (2) 实时流协议RTSP
        RTSP在体系结构上位于RTP和RTCP之上，它使用TCP或RTP完成数据传输
        该协议定义了如何在客户端与服务器之间建立/协商实时流通话

    (3) 资源预定协议RSVP
        属于网络层(IP、RSVP)
        使用RSVP预留一部分网络资源（即带宽），能在一定程度上为流媒体的传输提供QoS

    (4) 实时消息传输协议RTMP
        该协议基于TCP，是一个协议族。包括基本协议RTMP以及其变种，如RTMPT、RTMPS、RTMPE等
        主要是用于在「FLASH平台」和「流媒体服务器」之间进行音视频通信
```